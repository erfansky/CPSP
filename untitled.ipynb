{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset,random_split\n",
    "from torchvision.transforms import transforms\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sqlite3\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizerApply(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,vectorizer_type) -> None:\n",
    "        super().__init__()\n",
    "        self.vectoryzer_type = vectorizer_type\n",
    "        self.Vectorizers_ = None\n",
    "        self.dataset_columns_ = None\n",
    "        self.id_col_ = None\n",
    "        self.name_col_ = None\n",
    "        self.index_col_ = None\n",
    "\n",
    "    def fit(self,X:pd.DataFrame,y=None,**fit_params):\n",
    "        self.Vectorizers_ = []\n",
    "        self.id_col_ = fit_params['id']\n",
    "        self.name_col_ = fit_params['name']\n",
    "        self.index_col_ = fit_params['index']        \n",
    "        X = X.drop([fit_params['id'],fit_params['index'],fit_params['name']],axis=1)\n",
    "        self.dataset_columns_ = X.columns\n",
    "        for column in self.dataset_columns_:\n",
    "            X[column + 'ـseparate'] = X[column].apply(lambda x: x.replace('|',' '))\n",
    "            vectorizer = self.vectoryzer_type()\n",
    "            vectorizer.fit(X[column + 'ـseparate']).toarray()\n",
    "            self.Vectorizers_.append(vectorizer)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X:pd.DataFrame) -> pd.DataFrame:\n",
    "        result_columns = [self.id_col_,self.name_col_]\n",
    "        result_data = X[[self.id_col_,self.name_col_]].values\n",
    "        X = X.drop([self.id_col_,self.index_col_,self.name_col_],axis=1)\n",
    "        for i,column in enumerate(self.dataset_columns_):\n",
    "            X[column + 'ـseparate'] = X[column].apply(lambda x: x.replace('|',' '))\n",
    "            vectorizer = self.Vectorizers_[i]\n",
    "            data_matrix = vectorizer.transform(X[column + 'ـseparate']).toarray()\n",
    "            result_columns = result_columns + list(vectorizer.get_feature_names_out())\n",
    "            data_matrix[data_matrix > 1] = 1\n",
    "            result_data = np.concatenate((result_data,data_matrix),axis=1)\n",
    "        result_df = pd.DataFrame(data=result_data,columns=result_columns)\n",
    "        return result_df\n",
    "\n",
    "    def fit_transform(self, X:pd.DataFrame, y=None, **fit_params) -> pd.DataFrame:\n",
    "        self.Vectorizers_ = []\n",
    "        self.id_col_ = fit_params['id']\n",
    "        self.name_col_ = fit_params['name']\n",
    "        self.index_col_ = fit_params['index']        \n",
    "        result_columns = [fit_params['id'],fit_params['name']]\n",
    "        result_data = X[[fit_params['id'],fit_params['name']]].values\n",
    "        X = X.drop([fit_params['id'],fit_params['index'],fit_params['name']],axis=1)\n",
    "        self.dataset_columns_ = X.columns\n",
    "        for column in self.dataset_columns_:\n",
    "            X[column + 'ـseparate'] = X[column].apply(lambda x: x.replace('|',' '))\n",
    "            vectorizer = self.vectoryzer_type()\n",
    "            data_matrix = vectorizer.fit_transform(X[column + 'ـseparate']).toarray()\n",
    "            result_columns = result_columns + list(vectorizer.get_feature_names_out())\n",
    "            data_matrix[data_matrix > 1] = 1\n",
    "            result_data = np.concatenate((result_data,data_matrix),axis=1)\n",
    "            self.Vectorizers_.append(vectorizer)\n",
    "        result_df = pd.DataFrame(data=result_data,columns=result_columns)\n",
    "        return result_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Label_creator(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.interaction_list_ = None\n",
    "        self.index_col_ = None\n",
    "        self.mechanism_col_ = None\n",
    "        self.action_col_ = None\n",
    "\n",
    "    def fit(self,X:pd.DataFrame,y=None,**fit_params):\n",
    "        self.index_col_ = fit_params['index']\n",
    "        self.mechanism_col_= fit_params['mechanism']\n",
    "        self.action_col_ = fit_params['action']\n",
    "        self.interaction_list_ = list(set(X[self.mechanism_col_] + ' '+ X[self.action_col_]))\n",
    "\n",
    "    def transform(self,X:pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.drop([self.index_col_],axis=1)\n",
    "        X['interaction'] = X[self.mechanism_col_] + ' ' + X[self.action_col_]\n",
    "        X['interaction_numaber'] = list(map(lambda x : self.interaction_list_.index(x),X[self.mechanism_col_] + ' ' + X[self.action_col_]))\n",
    "        X = X.drop([self.mechanism_col_,self.action_col_],axis=1)\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X:pd.DataFrame, y=None, **fit_params) -> pd.DataFrame:\n",
    "        self.index_col_ = fit_params['index']\n",
    "        self.mechanism_col_= fit_params['mechanism']\n",
    "        self.action_col_ = fit_params['action']\n",
    "        self.interaction_list_ = list(set(X[self.mechanism_col_] + ' '+ X[self.action_col_]))\n",
    "        X = X.drop([self.index_col_],axis=1)\n",
    "        X['interaction'] = X[self.mechanism_col_] + ' ' + X[self.action_col_]\n",
    "        X['interaction_numaber'] = list(map(lambda x : self.interaction_list_.index(x),X[self.mechanism_col_] + ' ' + X[self.action_col_]))\n",
    "        X = X.drop([self.mechanism_col_,self.action_col_],axis=1)\n",
    "        return X\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugDataset(Dataset):\n",
    "\n",
    "    def __init__(self,X,y,**kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.pair_drugs = []\n",
    "        self.classes = [item[1] for item in sorted(set(zip(y['interaction_numaber'],y['interaction'])))]\n",
    "        self.class_to_idx = dict(set(zip(y['interaction'],y['interaction_numaber'])))\n",
    "        self.data = None\n",
    "        self.targets = None\n",
    "        final_X = []\n",
    "        final_y = []\n",
    "        for i in range(len(y)):\n",
    "            first_drug = y.loc[i,'drugA']\n",
    "            second_drug = y.loc[i,'drugB']\n",
    "            first_drug_vec = X[X['name']==first_drug].values[0]\n",
    "            second_drug_vec = X[X['name']== second_drug].values[0]\n",
    "            final_X.append(np.int32(np.vstack((first_drug_vec[2:],second_drug_vec[2:]))))\n",
    "            final_y.append(y.loc[i,'interaction_numaber'])\n",
    "            self.pair_drugs.append((first_drug,second_drug))\n",
    "            final_X.append(np.int32(np.vstack((second_drug_vec[2:],first_drug_vec[2:]))))\n",
    "            final_y.append(y.loc[i,'interaction_numaber'])\n",
    "            self.pair_drugs.append((second_drug,first_drug))\n",
    "            if os.name == 'nt':\n",
    "                if i%100 == 0:\n",
    "                    _ = os.system('cls')\n",
    "                    print(f'Process: {(i/len(y))*100} %')\n",
    "            else:\n",
    "                if i%100 == 0:\n",
    "                    _ = os.system('clear')\n",
    "                    print(f'Process: {(i/len(y))*100} %')\n",
    "            # if i % 100:\n",
    "            #     clear_output(wait=True)\n",
    "            #     print(f'Process: {(i/len(y))*100} %')\n",
    "        self.data = torch.Tensor(final_X)\n",
    "        self.targets = torch.Tensor(final_y).to(dtype=torch.int32)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index],self.targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>side</th>\n",
       "      <th>target</th>\n",
       "      <th>enzyme</th>\n",
       "      <th>pathway</th>\n",
       "      <th>smile</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DB01296</td>\n",
       "      <td>C1096328|C0162830|C1611725|C0541767|C0242973|C...</td>\n",
       "      <td>P14780|Q00653|P01375|P01579|P33673</td>\n",
       "      <td>P33261|P05181</td>\n",
       "      <td>hsa:4318|hsa:4791|hsa:7124|hsa:3458</td>\n",
       "      <td>9|10|14|18|19|20|178|181|283|284|285|286|299|3...</td>\n",
       "      <td>Glucosamine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DB09230</td>\n",
       "      <td>C0015371|C0949040|C0856054|C0231926|C1608969|C...</td>\n",
       "      <td>Q02641</td>\n",
       "      <td>P08684</td>\n",
       "      <td>hsa:782</td>\n",
       "      <td>9|10|11|12|13|14|15|16|18|19|20|129|131|132|17...</td>\n",
       "      <td>Azelnidipine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DB05812</td>\n",
       "      <td>C0341697|C0035232|C0855476|C0162119|C1142166|C...</td>\n",
       "      <td>P05093</td>\n",
       "      <td>P08684|Q06520|P10635|P10632|P05177|P33261|P11712</td>\n",
       "      <td>hsa:1586</td>\n",
       "      <td>9|10|11|12|14|18|143|147|178|179|182|183|184|1...</td>\n",
       "      <td>Abiraterone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DB01195</td>\n",
       "      <td>C1737214|C0015376|C0576091|C1536116|C0679254|C...</td>\n",
       "      <td>Q14524|P35499|Q12809</td>\n",
       "      <td>P10635|P11712</td>\n",
       "      <td>hsa:6331|hsa:6329|hsa:3757</td>\n",
       "      <td>9|10|11|12|14|15|18|19|23|24|25|178|180|181|18...</td>\n",
       "      <td>Flecainide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DB00201</td>\n",
       "      <td>C0423602|C0239557|C0031924|C0947912|C0600125|C...</td>\n",
       "      <td>P30542|P29274|Q07343|P21817|BE0004922|P78527|O...</td>\n",
       "      <td>P20815|P05177|P24462|P08684|P05181|P10632|P117...</td>\n",
       "      <td>hsa:134|hsa:135|hsa:5142|hsa:6261|hsa:5591|hsa...</td>\n",
       "      <td>9|10|11|14|15|16|18|19|143|148|149|178|183|184...</td>\n",
       "      <td>Caffeine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>DB01587</td>\n",
       "      <td>C0155867|C0341697|C0231341|C0853557|C0159060|C...</td>\n",
       "      <td>P30536|P14867|P18505|Q8N1C3|O14764|P78334</td>\n",
       "      <td>P08684</td>\n",
       "      <td>hsa:706|hsa:2554|hsa:2560|hsa:2565|hsa:2563|hs...</td>\n",
       "      <td>9|10|11|12|14|15|18|19|37|178|182|183|184|185|...</td>\n",
       "      <td>Ketazolam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>568</td>\n",
       "      <td>DB00448</td>\n",
       "      <td>C0241148|C0040440|C1096403|C0011253|C0001416|C...</td>\n",
       "      <td>P20648|P10636</td>\n",
       "      <td>P33261|P11712|P08684|P04798|P05177|Q16678|P332...</td>\n",
       "      <td>hsa:495|hsa:4137</td>\n",
       "      <td>9|10|11|12|14|15|18|19|23|24|33|143|148|149|17...</td>\n",
       "      <td>Lansoprazole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>569</td>\n",
       "      <td>DB00559</td>\n",
       "      <td>C0030283|C0856054|C0853557|C0426597|C0026636|C...</td>\n",
       "      <td>P25101|P24530</td>\n",
       "      <td>P08684|P11712</td>\n",
       "      <td>hsa:1909|hsa:1910</td>\n",
       "      <td>9|10|11|12|14|15|16|18|19|20|33|178|182|183|18...</td>\n",
       "      <td>Bosentan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>570</td>\n",
       "      <td>DB04953</td>\n",
       "      <td>C0238097|C1095952|C0558401|C0341217|C0154446|C...</td>\n",
       "      <td>O43526|O43525|P56696|Q9NR82</td>\n",
       "      <td>P22309|P35503|P22310|O60656|P11509|P11245</td>\n",
       "      <td>hsa:3785|hsa:3786|hsa:9132|hsa:56479</td>\n",
       "      <td>9|10|11|12|14|15|18|19|23|178|182|185|189|283|...</td>\n",
       "      <td>Ezogabine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>DB08865</td>\n",
       "      <td>C0267988|C0238097|C1608967|C0158820|C0855959|C...</td>\n",
       "      <td>Q9UM73|P08581</td>\n",
       "      <td>P08684|P20815|P20813</td>\n",
       "      <td>hsa:238|hsa:4233</td>\n",
       "      <td>9|10|11|12|14|15|16|18|23|37|38|143|148|149|17...</td>\n",
       "      <td>Crizotinib</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       id                                               side   \n",
       "0        0  DB01296  C1096328|C0162830|C1611725|C0541767|C0242973|C...  \\\n",
       "1        1  DB09230  C0015371|C0949040|C0856054|C0231926|C1608969|C...   \n",
       "2        2  DB05812  C0341697|C0035232|C0855476|C0162119|C1142166|C...   \n",
       "3        3  DB01195  C1737214|C0015376|C0576091|C1536116|C0679254|C...   \n",
       "4        4  DB00201  C0423602|C0239557|C0031924|C0947912|C0600125|C...   \n",
       "..     ...      ...                                                ...   \n",
       "567    567  DB01587  C0155867|C0341697|C0231341|C0853557|C0159060|C...   \n",
       "568    568  DB00448  C0241148|C0040440|C1096403|C0011253|C0001416|C...   \n",
       "569    569  DB00559  C0030283|C0856054|C0853557|C0426597|C0026636|C...   \n",
       "570    570  DB04953  C0238097|C1095952|C0558401|C0341217|C0154446|C...   \n",
       "571    571  DB08865  C0267988|C0238097|C1608967|C0158820|C0855959|C...   \n",
       "\n",
       "                                                target   \n",
       "0                   P14780|Q00653|P01375|P01579|P33673  \\\n",
       "1                                               Q02641   \n",
       "2                                               P05093   \n",
       "3                                 Q14524|P35499|Q12809   \n",
       "4    P30542|P29274|Q07343|P21817|BE0004922|P78527|O...   \n",
       "..                                                 ...   \n",
       "567          P30536|P14867|P18505|Q8N1C3|O14764|P78334   \n",
       "568                                      P20648|P10636   \n",
       "569                                      P25101|P24530   \n",
       "570                        O43526|O43525|P56696|Q9NR82   \n",
       "571                                      Q9UM73|P08581   \n",
       "\n",
       "                                                enzyme   \n",
       "0                                        P33261|P05181  \\\n",
       "1                                               P08684   \n",
       "2     P08684|Q06520|P10635|P10632|P05177|P33261|P11712   \n",
       "3                                        P10635|P11712   \n",
       "4    P20815|P05177|P24462|P08684|P05181|P10632|P117...   \n",
       "..                                                 ...   \n",
       "567                                             P08684   \n",
       "568  P33261|P11712|P08684|P04798|P05177|Q16678|P332...   \n",
       "569                                      P08684|P11712   \n",
       "570          P22309|P35503|P22310|O60656|P11509|P11245   \n",
       "571                               P08684|P20815|P20813   \n",
       "\n",
       "                                               pathway   \n",
       "0                  hsa:4318|hsa:4791|hsa:7124|hsa:3458  \\\n",
       "1                                              hsa:782   \n",
       "2                                             hsa:1586   \n",
       "3                           hsa:6331|hsa:6329|hsa:3757   \n",
       "4    hsa:134|hsa:135|hsa:5142|hsa:6261|hsa:5591|hsa...   \n",
       "..                                                 ...   \n",
       "567  hsa:706|hsa:2554|hsa:2560|hsa:2565|hsa:2563|hs...   \n",
       "568                                   hsa:495|hsa:4137   \n",
       "569                                  hsa:1909|hsa:1910   \n",
       "570               hsa:3785|hsa:3786|hsa:9132|hsa:56479   \n",
       "571                                   hsa:238|hsa:4233   \n",
       "\n",
       "                                                 smile          name  \n",
       "0    9|10|14|18|19|20|178|181|283|284|285|286|299|3...   Glucosamine  \n",
       "1    9|10|11|12|13|14|15|16|18|19|20|129|131|132|17...  Azelnidipine  \n",
       "2    9|10|11|12|14|18|143|147|178|179|182|183|184|1...   Abiraterone  \n",
       "3    9|10|11|12|14|15|18|19|23|24|25|178|180|181|18...    Flecainide  \n",
       "4    9|10|11|14|15|16|18|19|143|148|149|178|183|184...      Caffeine  \n",
       "..                                                 ...           ...  \n",
       "567  9|10|11|12|14|15|18|19|37|178|182|183|184|185|...     Ketazolam  \n",
       "568  9|10|11|12|14|15|18|19|23|24|33|143|148|149|17...  Lansoprazole  \n",
       "569  9|10|11|12|14|15|16|18|19|20|33|178|182|183|18...      Bosentan  \n",
       "570  9|10|11|12|14|15|18|19|23|178|182|185|189|283|...     Ezogabine  \n",
       "571  9|10|11|12|14|15|16|18|23|37|38|143|148|149|17...    Crizotinib  \n",
       "\n",
       "[572 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./DS1/df.pkl','rb') as f:\n",
    "    dataset = pickle.load(file=f)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>c0000727</th>\n",
       "      <th>c0000729</th>\n",
       "      <th>c0000733</th>\n",
       "      <th>c0000734</th>\n",
       "      <th>c0000735</th>\n",
       "      <th>c0000772</th>\n",
       "      <th>c0000809</th>\n",
       "      <th>c0000810</th>\n",
       "      <th>...</th>\n",
       "      <th>840</th>\n",
       "      <th>842</th>\n",
       "      <th>845</th>\n",
       "      <th>847</th>\n",
       "      <th>860</th>\n",
       "      <th>861</th>\n",
       "      <th>863</th>\n",
       "      <th>866</th>\n",
       "      <th>93</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB01296</td>\n",
       "      <td>Glucosamine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB09230</td>\n",
       "      <td>Azelnidipine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB05812</td>\n",
       "      <td>Abiraterone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB01195</td>\n",
       "      <td>Flecainide</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB00201</td>\n",
       "      <td>Caffeine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>DB01587</td>\n",
       "      <td>Ketazolam</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>DB00448</td>\n",
       "      <td>Lansoprazole</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>DB00559</td>\n",
       "      <td>Bosentan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>DB04953</td>\n",
       "      <td>Ezogabine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>DB08865</td>\n",
       "      <td>Crizotinib</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 12899 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          name c0000727 c0000729 c0000733 c0000734 c0000735   \n",
       "0    DB01296   Glucosamine        0        0        0        1        0  \\\n",
       "1    DB09230  Azelnidipine        0        0        0        0        0   \n",
       "2    DB05812   Abiraterone        0        0        0        0        0   \n",
       "3    DB01195    Flecainide        0        0        0        0        0   \n",
       "4    DB00201      Caffeine        0        0        0        0        0   \n",
       "..       ...           ...      ...      ...      ...      ...      ...   \n",
       "567  DB01587     Ketazolam        1        0        0        1        0   \n",
       "568  DB00448  Lansoprazole        0        1        0        0        0   \n",
       "569  DB00559      Bosentan        0        0        0        1        0   \n",
       "570  DB04953     Ezogabine        0        0        0        0        0   \n",
       "571  DB08865    Crizotinib        0        0        0        0        0   \n",
       "\n",
       "    c0000772 c0000809 c0000810  ... 840 842 845 847 860 861 863 866 93 95  \n",
       "0          0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "1          0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "2          0        0        0  ...   0   0   0   0   1   0   0   0  0  0  \n",
       "3          0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "4          0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "..       ...      ...      ...  ...  ..  ..  ..  ..  ..  ..  ..  .. .. ..  \n",
       "567        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "568        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "569        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "570        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "571        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "\n",
       "[572 rows x 12899 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = VectorizerApply(CountVectorizer)\n",
    "X = vec.fit_transform(dataset,id='id',index='index',name='name')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>action</th>\n",
       "      <th>drugA</th>\n",
       "      <th>drugB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The risk or severity of adverse effects</td>\n",
       "      <td>increase</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Amiodarone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Apalutamide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>increase</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Aprepitant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Atomoxetine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Bortezomib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37259</th>\n",
       "      <td>37259</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>increase</td>\n",
       "      <td>Nefazodone</td>\n",
       "      <td>Netupitant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37260</th>\n",
       "      <td>37260</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Nefazodone</td>\n",
       "      <td>Nicardipine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37261</th>\n",
       "      <td>37261</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>increase</td>\n",
       "      <td>Neratinib</td>\n",
       "      <td>Netupitant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37262</th>\n",
       "      <td>37262</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>increase</td>\n",
       "      <td>Netupitant</td>\n",
       "      <td>Nicardipine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37263</th>\n",
       "      <td>37263</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Nicardipine</td>\n",
       "      <td>Naproxen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37264 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                mechanism    action        drugA   \n",
       "0          0  The risk or severity of adverse effects  increase  Abemaciclib  \\\n",
       "1          1                  The serum concentration  decrease  Abemaciclib   \n",
       "2          2                  The serum concentration  increase  Abemaciclib   \n",
       "3          3                           The metabolism  decrease  Abemaciclib   \n",
       "4          4                           The metabolism  decrease  Abemaciclib   \n",
       "...      ...                                      ...       ...          ...   \n",
       "37259  37259                  The serum concentration  increase   Nefazodone   \n",
       "37260  37260                           The metabolism  decrease   Nefazodone   \n",
       "37261  37261                  The serum concentration  increase    Neratinib   \n",
       "37262  37262                  The serum concentration  increase   Netupitant   \n",
       "37263  37263                           The metabolism  decrease  Nicardipine   \n",
       "\n",
       "             drugB  \n",
       "0       Amiodarone  \n",
       "1      Apalutamide  \n",
       "2       Aprepitant  \n",
       "3      Atomoxetine  \n",
       "4       Bortezomib  \n",
       "...            ...  \n",
       "37259   Netupitant  \n",
       "37260  Nicardipine  \n",
       "37261   Netupitant  \n",
       "37262  Nicardipine  \n",
       "37263     Naproxen  \n",
       "\n",
       "[37264 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = sqlite3.connect('./DS1/event.db')\n",
    "extraction = pd.read_sql('select * from extraction;', connection)\n",
    "extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drugA</th>\n",
       "      <th>drugB</th>\n",
       "      <th>interaction</th>\n",
       "      <th>interaction_numaber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Amiodarone</td>\n",
       "      <td>The risk or severity of adverse effects increase</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Apalutamide</td>\n",
       "      <td>The serum concentration decrease</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Aprepitant</td>\n",
       "      <td>The serum concentration increase</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Atomoxetine</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Bortezomib</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37259</th>\n",
       "      <td>Nefazodone</td>\n",
       "      <td>Netupitant</td>\n",
       "      <td>The serum concentration increase</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37260</th>\n",
       "      <td>Nefazodone</td>\n",
       "      <td>Nicardipine</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37261</th>\n",
       "      <td>Neratinib</td>\n",
       "      <td>Netupitant</td>\n",
       "      <td>The serum concentration increase</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37262</th>\n",
       "      <td>Netupitant</td>\n",
       "      <td>Nicardipine</td>\n",
       "      <td>The serum concentration increase</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37263</th>\n",
       "      <td>Nicardipine</td>\n",
       "      <td>Naproxen</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37264 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             drugA        drugB   \n",
       "0      Abemaciclib   Amiodarone  \\\n",
       "1      Abemaciclib  Apalutamide   \n",
       "2      Abemaciclib   Aprepitant   \n",
       "3      Abemaciclib  Atomoxetine   \n",
       "4      Abemaciclib   Bortezomib   \n",
       "...            ...          ...   \n",
       "37259   Nefazodone   Netupitant   \n",
       "37260   Nefazodone  Nicardipine   \n",
       "37261    Neratinib   Netupitant   \n",
       "37262   Netupitant  Nicardipine   \n",
       "37263  Nicardipine     Naproxen   \n",
       "\n",
       "                                            interaction  interaction_numaber  \n",
       "0      The risk or severity of adverse effects increase                    4  \n",
       "1                      The serum concentration decrease                    6  \n",
       "2                      The serum concentration increase                   24  \n",
       "3                               The metabolism decrease                   63  \n",
       "4                               The metabolism decrease                   63  \n",
       "...                                                 ...                  ...  \n",
       "37259                  The serum concentration increase                   24  \n",
       "37260                           The metabolism decrease                   63  \n",
       "37261                  The serum concentration increase                   24  \n",
       "37262                  The serum concentration increase                   24  \n",
       "37263                           The metabolism decrease                   63  \n",
       "\n",
       "[37264 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_creator = Label_creator()\n",
    "y = label_creator.fit_transform(extraction,index='index',mechanism='mechanism',action='action')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 0.0 %\n",
      "Process: 0.2683555173894375 %\n",
      "Process: 0.536711034778875 %\n",
      "Process: 0.8050665521683126 %\n",
      "Process: 1.07342206955775 %\n",
      "Process: 1.3417775869471877 %\n",
      "Process: 1.6101331043366252 %\n",
      "Process: 1.8784886217260626 %\n",
      "Process: 2.1468441391155 %\n",
      "Process: 2.415199656504938 %\n",
      "Process: 2.6835551738943755 %\n",
      "Process: 2.9519106912838127 %\n",
      "Process: 3.2202662086732503 %\n",
      "Process: 3.488621726062688 %\n",
      "Process: 3.756977243452125 %\n",
      "Process: 4.025332760841563 %\n",
      "Process: 4.293688278231 %\n",
      "Process: 4.562043795620438 %\n",
      "Process: 4.830399313009876 %\n",
      "Process: 5.098754830399313 %\n",
      "Process: 5.367110347788751 %\n",
      "Process: 5.635465865178188 %\n",
      "Process: 5.903821382567625 %\n",
      "Process: 6.172176899957063 %\n",
      "Process: 6.440532417346501 %\n",
      "Process: 6.708887934735938 %\n",
      "Process: 6.977243452125376 %\n",
      "Process: 7.2455989695148135 %\n",
      "Process: 7.51395448690425 %\n",
      "Process: 7.782310004293688 %\n",
      "Process: 8.050665521683126 %\n",
      "Process: 8.319021039072563 %\n",
      "Process: 8.587376556462 %\n",
      "Process: 8.855732073851438 %\n",
      "Process: 9.124087591240876 %\n",
      "Process: 9.392443108630314 %\n",
      "Process: 9.660798626019751 %\n",
      "Process: 9.929154143409189 %\n",
      "Process: 10.197509660798627 %\n",
      "Process: 10.465865178188064 %\n",
      "Process: 10.734220695577502 %\n",
      "Process: 11.002576212966938 %\n",
      "Process: 11.270931730356375 %\n",
      "Process: 11.539287247745813 %\n",
      "Process: 11.80764276513525 %\n",
      "Process: 12.075998282524688 %\n",
      "Process: 12.344353799914126 %\n",
      "Process: 12.612709317303564 %\n",
      "Process: 12.881064834693001 %\n",
      "Process: 13.149420352082439 %\n",
      "Process: 13.417775869471877 %\n",
      "Process: 13.686131386861314 %\n",
      "Process: 13.954486904250752 %\n",
      "Process: 14.22284242164019 %\n",
      "Process: 14.491197939029627 %\n",
      "Process: 14.759553456419065 %\n",
      "Process: 15.0279089738085 %\n",
      "Process: 15.296264491197938 %\n",
      "Process: 15.564620008587376 %\n",
      "Process: 15.832975525976813 %\n",
      "Process: 16.10133104336625 %\n",
      "Process: 16.36968656075569 %\n",
      "Process: 16.638042078145126 %\n",
      "Process: 16.906397595534564 %\n",
      "Process: 17.174753112924 %\n",
      "Process: 17.44310863031344 %\n",
      "Process: 17.711464147702877 %\n",
      "Process: 17.979819665092315 %\n",
      "Process: 18.248175182481752 %\n",
      "Process: 18.51653069987119 %\n",
      "Process: 18.784886217260627 %\n",
      "Process: 19.053241734650065 %\n",
      "Process: 19.321597252039503 %\n",
      "Process: 19.58995276942894 %\n",
      "Process: 19.858308286818378 %\n",
      "Process: 20.126663804207816 %\n",
      "Process: 20.395019321597253 %\n",
      "Process: 20.66337483898669 %\n",
      "Process: 20.93173035637613 %\n",
      "Process: 21.200085873765566 %\n",
      "Process: 21.468441391155004 %\n",
      "Process: 21.736796908544438 %\n",
      "Process: 22.005152425933876 %\n",
      "Process: 22.273507943323313 %\n",
      "Process: 22.54186346071275 %\n",
      "Process: 22.81021897810219 %\n",
      "Process: 23.078574495491626 %\n",
      "Process: 23.346930012881064 %\n",
      "Process: 23.6152855302705 %\n",
      "Process: 23.88364104765994 %\n",
      "Process: 24.151996565049377 %\n",
      "Process: 24.420352082438814 %\n",
      "Process: 24.688707599828252 %\n",
      "Process: 24.95706311721769 %\n",
      "Process: 25.225418634607127 %\n",
      "Process: 25.49377415199657 %\n",
      "Process: 25.762129669386002 %\n",
      "Process: 26.030485186775444 %\n",
      "Process: 26.298840704164878 %\n",
      "Process: 26.56719622155432 %\n",
      "Process: 26.835551738943753 %\n",
      "Process: 27.103907256333194 %\n",
      "Process: 27.37226277372263 %\n",
      "Process: 27.64061829111207 %\n",
      "Process: 27.908973808501504 %\n",
      "Process: 28.177329325890945 %\n",
      "Process: 28.44568484328038 %\n",
      "Process: 28.714040360669816 %\n",
      "Process: 28.982395878059254 %\n",
      "Process: 29.25075139544869 %\n",
      "Process: 29.51910691283813 %\n",
      "Process: 29.787462430227567 %\n",
      "Process: 30.055817947617 %\n",
      "Process: 30.324173465006442 %\n",
      "Process: 30.592528982395876 %\n",
      "Process: 30.860884499785318 %\n",
      "Process: 31.12924001717475 %\n",
      "Process: 31.397595534564193 %\n",
      "Process: 31.665951051953627 %\n",
      "Process: 31.934306569343068 %\n",
      "Process: 32.2026620867325 %\n",
      "Process: 32.47101760412194 %\n",
      "Process: 32.73937312151138 %\n",
      "Process: 33.007728638900815 %\n",
      "Process: 33.27608415629025 %\n",
      "Process: 33.54443967367969 %\n",
      "Process: 33.81279519106913 %\n",
      "Process: 34.081150708458566 %\n",
      "Process: 34.349506225848 %\n",
      "Process: 34.61786174323744 %\n",
      "Process: 34.88621726062688 %\n",
      "Process: 35.154572778016316 %\n",
      "Process: 35.422928295405754 %\n",
      "Process: 35.69128381279519 %\n",
      "Process: 35.95963933018463 %\n",
      "Process: 36.22799484757407 %\n",
      "Process: 36.496350364963504 %\n",
      "Process: 36.76470588235294 %\n",
      "Process: 37.03306139974238 %\n",
      "Process: 37.30141691713182 %\n",
      "Process: 37.569772434521255 %\n",
      "Process: 37.83812795191069 %\n",
      "Process: 38.10648346930013 %\n",
      "Process: 38.37483898668957 %\n",
      "Process: 38.643194504079005 %\n",
      "Process: 38.91155002146844 %\n",
      "Process: 39.17990553885788 %\n",
      "Process: 39.44826105624732 %\n",
      "Process: 39.716616573636756 %\n",
      "Process: 39.984972091026194 %\n",
      "Process: 40.25332760841563 %\n",
      "Process: 40.52168312580507 %\n",
      "Process: 40.79003864319451 %\n",
      "Process: 41.058394160583944 %\n",
      "Process: 41.32674967797338 %\n",
      "Process: 41.59510519536282 %\n",
      "Process: 41.86346071275226 %\n",
      "Process: 42.131816230141695 %\n",
      "Process: 42.40017174753113 %\n",
      "Process: 42.66852726492057 %\n",
      "Process: 42.93688278231001 %\n",
      "Process: 43.205238299699445 %\n",
      "Process: 43.473593817088876 %\n",
      "Process: 43.74194933447832 %\n",
      "Process: 44.01030485186775 %\n",
      "Process: 44.278660369257196 %\n",
      "Process: 44.547015886646626 %\n",
      "Process: 44.81537140403607 %\n",
      "Process: 45.0837269214255 %\n",
      "Process: 45.352082438814946 %\n",
      "Process: 45.62043795620438 %\n",
      "Process: 45.88879347359382 %\n",
      "Process: 46.15714899098325 %\n",
      "Process: 46.4255045083727 %\n",
      "Process: 46.69386002576213 %\n",
      "Process: 46.96221554315157 %\n",
      "Process: 47.230571060541 %\n",
      "Process: 47.49892657793045 %\n",
      "Process: 47.76728209531988 %\n",
      "Process: 48.03563761270932 %\n",
      "Process: 48.30399313009875 %\n",
      "Process: 48.5723486474882 %\n",
      "Process: 48.84070416487763 %\n",
      "Process: 49.10905968226707 %\n",
      "Process: 49.377415199656504 %\n",
      "Process: 49.64577071704595 %\n",
      "Process: 49.91412623443538 %\n",
      "Process: 50.18248175182482 %\n",
      "Process: 50.450837269214254 %\n",
      "Process: 50.71919278660369 %\n",
      "Process: 50.98754830399314 %\n",
      "Process: 51.25590382138257 %\n",
      "Process: 51.524259338772005 %\n",
      "Process: 51.79261485616144 %\n",
      "Process: 52.06097037355089 %\n",
      "Process: 52.32932589094032 %\n",
      "Process: 52.597681408329755 %\n",
      "Process: 52.86603692571919 %\n",
      "Process: 53.13439244310864 %\n",
      "Process: 53.40274796049806 %\n",
      "Process: 53.671103477887506 %\n",
      "Process: 53.939458995276944 %\n",
      "Process: 54.20781451266639 %\n",
      "Process: 54.47617003005581 %\n",
      "Process: 54.74452554744526 %\n",
      "Process: 55.012881064834694 %\n",
      "Process: 55.28123658222414 %\n",
      "Process: 55.54959209961356 %\n",
      "Process: 55.81794761700301 %\n",
      "Process: 56.086303134392445 %\n",
      "Process: 56.35465865178189 %\n",
      "Process: 56.62301416917131 %\n",
      "Process: 56.89136968656076 %\n",
      "Process: 57.159725203950195 %\n",
      "Process: 57.42808072133963 %\n",
      "Process: 57.69643623872906 %\n",
      "Process: 57.96479175611851 %\n",
      "Process: 58.233147273507946 %\n",
      "Process: 58.50150279089738 %\n",
      "Process: 58.769858308286814 %\n",
      "Process: 59.03821382567626 %\n",
      "Process: 59.306569343065696 %\n",
      "Process: 59.574924860455134 %\n",
      "Process: 59.843280377844565 %\n",
      "Process: 60.111635895234 %\n",
      "Process: 60.37999141262345 %\n",
      "Process: 60.648346930012885 %\n",
      "Process: 60.916702447402315 %\n",
      "Process: 61.18505796479175 %\n",
      "Process: 61.4534134821812 %\n",
      "Process: 61.721768999570635 %\n",
      "Process: 61.990124516960066 %\n",
      "Process: 62.2584800343495 %\n",
      "Process: 62.52683555173895 %\n",
      "Process: 62.795191069128386 %\n",
      "Process: 63.063546586517816 %\n",
      "Process: 63.331902103907254 %\n",
      "Process: 63.6002576212967 %\n",
      "Process: 63.868613138686136 %\n",
      "Process: 64.13696865607557 %\n",
      "Process: 64.405324173465 %\n",
      "Process: 64.67367969085444 %\n",
      "Process: 64.94203520824388 %\n",
      "Process: 65.21039072563332 %\n",
      "Process: 65.47874624302275 %\n",
      "Process: 65.74710176041219 %\n",
      "Process: 66.01545727780163 %\n",
      "Process: 66.28381279519107 %\n",
      "Process: 66.5521683125805 %\n",
      "Process: 66.82052382996994 %\n",
      "Process: 67.08887934735938 %\n",
      "Process: 67.35723486474882 %\n",
      "Process: 67.62559038213826 %\n",
      "Process: 67.8939458995277 %\n",
      "Process: 68.16230141691713 %\n",
      "Process: 68.43065693430657 %\n",
      "Process: 68.699012451696 %\n",
      "Process: 68.96736796908544 %\n",
      "Process: 69.23572348647488 %\n",
      "Process: 69.50407900386432 %\n",
      "Process: 69.77243452125376 %\n",
      "Process: 70.0407900386432 %\n",
      "Process: 70.30914555603263 %\n",
      "Process: 70.57750107342207 %\n",
      "Process: 70.84585659081151 %\n",
      "Process: 71.11421210820095 %\n",
      "Process: 71.38256762559038 %\n",
      "Process: 71.65092314297982 %\n",
      "Process: 71.91927866036926 %\n",
      "Process: 72.1876341777587 %\n",
      "Process: 72.45598969514813 %\n",
      "Process: 72.72434521253757 %\n",
      "Process: 72.99270072992701 %\n",
      "Process: 73.26105624731645 %\n",
      "Process: 73.52941176470588 %\n",
      "Process: 73.79776728209532 %\n",
      "Process: 74.06612279948476 %\n",
      "Process: 74.3344783168742 %\n",
      "Process: 74.60283383426363 %\n",
      "Process: 74.87118935165307 %\n",
      "Process: 75.13954486904251 %\n",
      "Process: 75.40790038643195 %\n",
      "Process: 75.67625590382139 %\n",
      "Process: 75.94461142121082 %\n",
      "Process: 76.21296693860026 %\n",
      "Process: 76.4813224559897 %\n",
      "Process: 76.74967797337914 %\n",
      "Process: 77.01803349076857 %\n",
      "Process: 77.28638900815801 %\n",
      "Process: 77.55474452554745 %\n",
      "Process: 77.82310004293689 %\n",
      "Process: 78.09145556032632 %\n",
      "Process: 78.35981107771576 %\n",
      "Process: 78.6281665951052 %\n",
      "Process: 78.89652211249464 %\n",
      "Process: 79.16487762988407 %\n",
      "Process: 79.43323314727351 %\n",
      "Process: 79.70158866466295 %\n",
      "Process: 79.96994418205239 %\n",
      "Process: 80.23829969944181 %\n",
      "Process: 80.50665521683126 %\n",
      "Process: 80.7750107342207 %\n",
      "Process: 81.04336625161014 %\n",
      "Process: 81.31172176899956 %\n",
      "Process: 81.58007728638901 %\n",
      "Process: 81.84843280377845 %\n",
      "Process: 82.11678832116789 %\n",
      "Process: 82.38514383855731 %\n",
      "Process: 82.65349935594676 %\n",
      "Process: 82.9218548733362 %\n",
      "Process: 83.19021039072564 %\n",
      "Process: 83.45856590811506 %\n",
      "Process: 83.72692142550451 %\n",
      "Process: 83.99527694289395 %\n",
      "Process: 84.26363246028339 %\n",
      "Process: 84.53198797767281 %\n",
      "Process: 84.80034349506226 %\n",
      "Process: 85.0686990124517 %\n",
      "Process: 85.33705452984114 %\n",
      "Process: 85.60541004723056 %\n",
      "Process: 85.87376556462002 %\n",
      "Process: 86.14212108200945 %\n",
      "Process: 86.41047659939889 %\n",
      "Process: 86.67883211678831 %\n",
      "Process: 86.94718763417775 %\n",
      "Process: 87.2155431515672 %\n",
      "Process: 87.48389866895664 %\n",
      "Process: 87.75225418634606 %\n",
      "Process: 88.0206097037355 %\n",
      "Process: 88.28896522112495 %\n",
      "Process: 88.55732073851439 %\n",
      "Process: 88.82567625590382 %\n",
      "Process: 89.09403177329325 %\n",
      "Process: 89.3623872906827 %\n",
      "Process: 89.63074280807214 %\n",
      "Process: 89.89909832546157 %\n",
      "Process: 90.167453842851 %\n",
      "Process: 90.43580936024046 %\n",
      "Process: 90.70416487762989 %\n",
      "Process: 90.97252039501932 %\n",
      "Process: 91.24087591240875 %\n",
      "Process: 91.5092314297982 %\n",
      "Process: 91.77758694718764 %\n",
      "Process: 92.04594246457707 %\n",
      "Process: 92.3142979819665 %\n",
      "Process: 92.58265349935596 %\n",
      "Process: 92.8510090167454 %\n",
      "Process: 93.11936453413482 %\n",
      "Process: 93.38772005152425 %\n",
      "Process: 93.65607556891369 %\n",
      "Process: 93.92443108630314 %\n",
      "Process: 94.19278660369257 %\n",
      "Process: 94.461142121082 %\n",
      "Process: 94.72949763847144 %\n",
      "Process: 94.9978531558609 %\n",
      "Process: 95.26620867325032 %\n",
      "Process: 95.53456419063976 %\n",
      "Process: 95.8029197080292 %\n",
      "Process: 96.07127522541865 %\n",
      "Process: 96.33963074280807 %\n",
      "Process: 96.6079862601975 %\n",
      "Process: 96.87634177758694 %\n",
      "Process: 97.1446972949764 %\n",
      "Process: 97.41305281236582 %\n",
      "Process: 97.68140832975526 %\n",
      "Process: 97.9497638471447 %\n",
      "Process: 98.21811936453415 %\n",
      "Process: 98.48647488192357 %\n",
      "Process: 98.75483039931301 %\n",
      "Process: 99.02318591670245 %\n",
      "Process: 99.2915414340919 %\n",
      "Process: 99.55989695148132 %\n",
      "Process: 99.82825246887076 %\n"
     ]
    }
   ],
   "source": [
    "drug_dataset = DrugDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "if not os.path.exists('./saved_dataset/'):\n",
    "    os.makedirs('./saved_dataset/')\n",
    "\n",
    "with open('./saved_dataset/drug_dataset.pickle','wb') as f:\n",
    "    pickle.dump(drug_dataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to train and validation section\n",
    "train_size = int(0.8 * len(drug_dataset))\n",
    "val_size = len(drug_dataset) - train_size\n",
    "\n",
    "train_dataset , val_dataset = random_split(drug_dataset,lengths=[train_size,val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader for train loader and val loader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning module\n",
    "\n",
    "class CPSP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,conv_mid_channel,out_dim,*args, **kwargs) -> None:\n",
    "        super(CPSP,self).__init__(*args, **kwargs)\n",
    "        self.conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=conv_mid_channel,kernel_size=(2,3),stride=2)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(conv_mid_channel)\n",
    "        self.conv1_1 = torch.nn.Conv2d(in_channels=conv_mid_channel,out_channels=1, kernel_size=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(1)\n",
    "        self.fc1 = torch.nn.Linear(6448, 2048)\n",
    "        self.fc2 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc3 = torch.nn.Linear(1024, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1_1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = x.view(-1,int(x.nelement() / x.shape[0]))\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 1.3171025156047218 Val Loss: 0.8245241704033168\n",
      "Epoch: 1 Train Loss: 0.7067390859191015 Val Loss: 0.622211436393307\n",
      "Epoch: 2 Train Loss: 0.5587394935607927 Val Loss: 0.5486049201307507\n",
      "Epoch: 3 Train Loss: 0.47253441559723053 Val Loss: 0.4700812046603967\n",
      "Epoch: 4 Train Loss: 0.4036195465101932 Val Loss: 0.4319542506150102\n",
      "Epoch: 5 Train Loss: 0.34331930259521026 Val Loss: 0.3640920912303318\n",
      "Epoch: 6 Train Loss: 0.28537669621342016 Val Loss: 0.3297004930059477\n",
      "Epoch: 7 Train Loss: 0.234158639757346 Val Loss: 0.27890224731427343\n",
      "Epoch: 8 Train Loss: 0.1875623720596855 Val Loss: 0.23901614176445188\n",
      "Epoch: 9 Train Loss: 0.14708658441204528 Val Loss: 0.2167630347936882\n",
      "Epoch: 10 Train Loss: 0.11261952902146158 Val Loss: 0.1890209762643335\n",
      "Epoch: 11 Train Loss: 0.0878823318116133 Val Loss: 0.15990529475781604\n",
      "Epoch: 12 Train Loss: 0.06397854240051702 Val Loss: 0.1433683533352388\n",
      "Epoch: 13 Train Loss: 0.04877701456346373 Val Loss: 0.12246843920710852\n",
      "Epoch: 14 Train Loss: 0.03692685659319614 Val Loss: 0.1266248581367405\n"
     ]
    }
   ],
   "source": [
    "# create model and train loop\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CPSP(1,3,65).to(device=device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.0001,momentum=0.9)\n",
    "\n",
    "N_epochs = 100\n",
    "\n",
    "pre_val_loss = np.inf\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "    if val_loss >= pre_val_loss:\n",
    "        print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(epoch,\n",
    "                                                         train_loss/len(train_loader),\n",
    "                                                         val_loss/len(val_loader)))\n",
    "        break\n",
    "    else:\n",
    "        pre_val_loss = val_loss\n",
    "        print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(epoch,\n",
    "                                                         train_loss/len(train_loader),\n",
    "                                                         val_loss/len(val_loader)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to save the model\n",
    "PATH = \"./saved_dataset/model.pt\"\n",
    "# Save the model state dictionary\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trian Accuracy: 99.27%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computations\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        # Move images and labels to the device (e.g. GPU) if available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass to get model predictions\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get the predicted class for each image\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Count the number of correct predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Count the total number of images\n",
    "        total += labels.size(0)\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = correct / total\n",
    "print('trian Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Accuracy: 96.59%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computations\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        # Move images and labels to the device (e.g. GPU) if available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass to get model predictions\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get the predicted class for each image\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Count the number of correct predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Count the total number of images\n",
    "        total += labels.size(0)\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = correct / total\n",
    "print('validation Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
