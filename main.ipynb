{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset,random_split,ConcatDataset\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sqlite3\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torcheval.metrics.functional as tce\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizerApply(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,vectorizer_type) -> None:\n",
    "        super().__init__()\n",
    "        self.vectoryzer_type = vectorizer_type\n",
    "        self.Vectorizers_ = None\n",
    "        self.dataset_columns_ = None\n",
    "        self.id_col_ = None\n",
    "        self.name_col_ = None\n",
    "        self.index_col_ = None\n",
    "\n",
    "    def fit(self,X:pd.DataFrame,y=None,**fit_params):\n",
    "        self.Vectorizers_ = []\n",
    "        self.id_col_ = fit_params['id']\n",
    "        self.name_col_ = fit_params['name']\n",
    "        self.index_col_ = fit_params['index']        \n",
    "        X = X.drop([fit_params['id'],fit_params['index'],fit_params['name']],axis=1)\n",
    "        self.dataset_columns_ = X.columns\n",
    "        for column in self.dataset_columns_:\n",
    "            X[column + 'ـseparate'] = X[column].apply(lambda x: x.replace('|',' '))\n",
    "            vectorizer = self.vectoryzer_type()\n",
    "            vectorizer.fit(X[column + 'ـseparate']).toarray()\n",
    "            self.Vectorizers_.append(vectorizer)\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X:pd.DataFrame) -> pd.DataFrame:\n",
    "        result_columns = [self.id_col_,self.name_col_]\n",
    "        result_data = X[[self.id_col_,self.name_col_]].values\n",
    "        X = X.drop([self.id_col_,self.index_col_,self.name_col_],axis=1)\n",
    "        for i,column in enumerate(self.dataset_columns_):\n",
    "            X[column + 'ـseparate'] = X[column].apply(lambda x: x.replace('|',' '))\n",
    "            vectorizer = self.Vectorizers_[i]\n",
    "            data_matrix = vectorizer.transform(X[column + 'ـseparate']).toarray()\n",
    "            result_columns = result_columns + list(vectorizer.get_feature_names_out())\n",
    "            data_matrix[data_matrix > 1] = 1\n",
    "            result_data = np.concatenate((result_data,data_matrix),axis=1)\n",
    "        result_df = pd.DataFrame(data=result_data,columns=result_columns)\n",
    "        return result_df\n",
    "\n",
    "    def fit_transform(self, X:pd.DataFrame, y=None, **fit_params) -> pd.DataFrame:\n",
    "        self.Vectorizers_ = []\n",
    "        self.id_col_ = fit_params['id']\n",
    "        self.name_col_ = fit_params['name']\n",
    "        self.index_col_ = fit_params['index']        \n",
    "        result_columns = [fit_params['id'],fit_params['name']]\n",
    "        result_data = X[[fit_params['id'],fit_params['name']]].values\n",
    "        X = X.drop([fit_params['id'],fit_params['index'],fit_params['name']],axis=1)\n",
    "        self.dataset_columns_ = X.columns\n",
    "        for column in self.dataset_columns_:\n",
    "            X[column + 'ـseparate'] = X[column].apply(lambda x: x.replace('|',' '))\n",
    "            vectorizer = self.vectoryzer_type()\n",
    "            data_matrix = vectorizer.fit_transform(X[column + 'ـseparate']).toarray()\n",
    "            result_columns = result_columns + list(vectorizer.get_feature_names_out())\n",
    "            data_matrix[data_matrix > 1] = 1\n",
    "            result_data = np.concatenate((result_data,data_matrix),axis=1)\n",
    "            self.Vectorizers_.append(vectorizer)\n",
    "        result_df = pd.DataFrame(data=result_data,columns=result_columns)\n",
    "        return result_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device,num_classes):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            if y_pred is None:\n",
    "                y_pred = outputs\n",
    "            else:\n",
    "                y_pred = torch.vstack((y_pred,outputs))\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_pred_final = []\n",
    "    y_true_final = []\n",
    "    for i in range(len(y_true)):\n",
    "      y_true_final.append(y_true[i] + 1)\n",
    "    for i in range(len(y_pred)):\n",
    "      y_pred_final.append(y_pred[i] + 1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_true_final, y_pred_final)\n",
    "    \n",
    "    # calculate f1_score\n",
    "    f1_score_result = f1_score(y_true_final, y_pred_final, average='macro')\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_true_final, y_pred_final, average='macro', zero_division = 0)\n",
    "\n",
    "    # calculate recall\n",
    "    recall = recall_score(y_true_final, y_pred_final, average='macro')\n",
    "    \n",
    "    return acc, f1_score_result, precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Label_creator(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.interaction_list_ = None\n",
    "        self.index_col_ = None\n",
    "        self.mechanism_col_ = None\n",
    "        self.action_col_ = None\n",
    "\n",
    "    def fit(self,X:pd.DataFrame,y=None,**fit_params):\n",
    "        self.index_col_ = fit_params['index']\n",
    "        self.mechanism_col_= fit_params['mechanism']\n",
    "        self.action_col_ = fit_params['action']\n",
    "        self.interaction_list_ = list(set(X[self.mechanism_col_] + ' '+ X[self.action_col_]))\n",
    "\n",
    "    def transform(self,X:pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.drop([self.index_col_],axis=1)\n",
    "        X['interaction'] = X[self.mechanism_col_] + ' ' + X[self.action_col_]\n",
    "        X['interaction_numaber'] = list(map(lambda x : self.interaction_list_.index(x),X[self.mechanism_col_] + ' ' + X[self.action_col_]))\n",
    "        X = X.drop([self.mechanism_col_,self.action_col_],axis=1)\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X:pd.DataFrame, y=None, **fit_params) -> pd.DataFrame:\n",
    "        self.index_col_ = fit_params['index']\n",
    "        self.mechanism_col_= fit_params['mechanism']\n",
    "        self.action_col_ = fit_params['action']\n",
    "        self.interaction_list_ = list(set(X[self.mechanism_col_] + ' '+ X[self.action_col_]))\n",
    "        X = X.drop([self.index_col_],axis=1)\n",
    "        X['interaction'] = X[self.mechanism_col_] + ' ' + X[self.action_col_]\n",
    "        X['interaction_numaber'] = list(map(lambda x : self.interaction_list_.index(x),X[self.mechanism_col_] + ' ' + X[self.action_col_]))\n",
    "        X = X.drop([self.mechanism_col_,self.action_col_],axis=1)\n",
    "        return X\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugDataset(Dataset):\n",
    "\n",
    "    def __init__(self,X,y,**kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.pair_drugs = []\n",
    "        self.classes = [item[1] for item in sorted(set(zip(y['interaction_numaber'],y['interaction'])))]\n",
    "        self.class_to_idx = dict(set(zip(y['interaction'],y['interaction_numaber'])))\n",
    "        self.data = None\n",
    "        self.targets = None\n",
    "        final_X = []\n",
    "        final_y = []\n",
    "        for i in range(len(y)):\n",
    "            first_drug = y.loc[i,'drugA']\n",
    "            second_drug = y.loc[i,'drugB']\n",
    "            first_drug_vec = X[X['name']==first_drug].values[0]\n",
    "            second_drug_vec = X[X['name']== second_drug].values[0]\n",
    "            final_X.append(np.int32(np.vstack((first_drug_vec[2:],second_drug_vec[2:]))))\n",
    "            final_y.append(y.loc[i,'interaction_numaber'])\n",
    "            self.pair_drugs.append((first_drug,second_drug))\n",
    "            if os.name == 'nt':\n",
    "                if i%1000 == 0:\n",
    "                    _ = os.system('cls')\n",
    "                    print(f'Process: {(i/len(y))*100} %')\n",
    "            else:\n",
    "                if i%1000 == 0:\n",
    "                    _ = os.system('clear')\n",
    "                    print(f'Process: {(i/len(y))*100} %')\n",
    "        self.data = np.array(final_X)\n",
    "        self.data = torch.Tensor(self.data).to(dtype=torch.float32)\n",
    "        self.targets = torch.Tensor(final_y).to(dtype=torch.int32)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index],self.targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetWithTransform(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.dataset[index]\n",
    "        return self.transform(x), y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_concat(dataset):\n",
    "    transform = transforms.RandomVerticalFlip(p=1)\n",
    "    augmented_dataset = DatasetWithTransform(dataset=dataset,transform=transform)\n",
    "    return ConcatDataset(datasets=[dataset,augmented_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning module\n",
    "\n",
    "class CPSP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,feature_size,in_channels,conv_mid_channel,out_dim,*args, **kwargs) -> None:\n",
    "        super(CPSP,self).__init__(*args, **kwargs)\n",
    "        self.conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=conv_mid_channel,kernel_size=(2,3),stride=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(conv_mid_channel)\n",
    "        self.conv1_1 = torch.nn.Conv2d(in_channels=conv_mid_channel,out_channels=1, kernel_size=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(1)\n",
    "        self.fc1 = torch.nn.Linear((feature_size-3)//1 + 1, 2048)\n",
    "        self.fc2 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc3 = torch.nn.Linear(1024, out_dim)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.5)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1_1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = x.view(-1,int(x.nelement() / x.shape[0]))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>side</th>\n",
       "      <th>target</th>\n",
       "      <th>enzyme</th>\n",
       "      <th>pathway</th>\n",
       "      <th>smile</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DB01296</td>\n",
       "      <td>C1096328|C0162830|C1611725|C0541767|C0242973|C...</td>\n",
       "      <td>P14780|Q00653|P01375|P01579|P33673</td>\n",
       "      <td>P33261|P05181</td>\n",
       "      <td>hsa:4318|hsa:4791|hsa:7124|hsa:3458</td>\n",
       "      <td>9|10|14|18|19|20|178|181|283|284|285|286|299|3...</td>\n",
       "      <td>Glucosamine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DB09230</td>\n",
       "      <td>C0015371|C0949040|C0856054|C0231926|C1608969|C...</td>\n",
       "      <td>Q02641</td>\n",
       "      <td>P08684</td>\n",
       "      <td>hsa:782</td>\n",
       "      <td>9|10|11|12|13|14|15|16|18|19|20|129|131|132|17...</td>\n",
       "      <td>Azelnidipine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DB05812</td>\n",
       "      <td>C0341697|C0035232|C0855476|C0162119|C1142166|C...</td>\n",
       "      <td>P05093</td>\n",
       "      <td>P08684|Q06520|P10635|P10632|P05177|P33261|P11712</td>\n",
       "      <td>hsa:1586</td>\n",
       "      <td>9|10|11|12|14|18|143|147|178|179|182|183|184|1...</td>\n",
       "      <td>Abiraterone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DB01195</td>\n",
       "      <td>C1737214|C0015376|C0576091|C1536116|C0679254|C...</td>\n",
       "      <td>Q14524|P35499|Q12809</td>\n",
       "      <td>P10635|P11712</td>\n",
       "      <td>hsa:6331|hsa:6329|hsa:3757</td>\n",
       "      <td>9|10|11|12|14|15|18|19|23|24|25|178|180|181|18...</td>\n",
       "      <td>Flecainide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DB00201</td>\n",
       "      <td>C0423602|C0239557|C0031924|C0947912|C0600125|C...</td>\n",
       "      <td>P30542|P29274|Q07343|P21817|BE0004922|P78527|O...</td>\n",
       "      <td>P20815|P05177|P24462|P08684|P05181|P10632|P117...</td>\n",
       "      <td>hsa:134|hsa:135|hsa:5142|hsa:6261|hsa:5591|hsa...</td>\n",
       "      <td>9|10|11|14|15|16|18|19|143|148|149|178|183|184...</td>\n",
       "      <td>Caffeine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>DB01587</td>\n",
       "      <td>C0155867|C0341697|C0231341|C0853557|C0159060|C...</td>\n",
       "      <td>P30536|P14867|P18505|Q8N1C3|O14764|P78334</td>\n",
       "      <td>P08684</td>\n",
       "      <td>hsa:706|hsa:2554|hsa:2560|hsa:2565|hsa:2563|hs...</td>\n",
       "      <td>9|10|11|12|14|15|18|19|37|178|182|183|184|185|...</td>\n",
       "      <td>Ketazolam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>568</td>\n",
       "      <td>DB00448</td>\n",
       "      <td>C0241148|C0040440|C1096403|C0011253|C0001416|C...</td>\n",
       "      <td>P20648|P10636</td>\n",
       "      <td>P33261|P11712|P08684|P04798|P05177|Q16678|P332...</td>\n",
       "      <td>hsa:495|hsa:4137</td>\n",
       "      <td>9|10|11|12|14|15|18|19|23|24|33|143|148|149|17...</td>\n",
       "      <td>Lansoprazole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>569</td>\n",
       "      <td>DB00559</td>\n",
       "      <td>C0030283|C0856054|C0853557|C0426597|C0026636|C...</td>\n",
       "      <td>P25101|P24530</td>\n",
       "      <td>P08684|P11712</td>\n",
       "      <td>hsa:1909|hsa:1910</td>\n",
       "      <td>9|10|11|12|14|15|16|18|19|20|33|178|182|183|18...</td>\n",
       "      <td>Bosentan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>570</td>\n",
       "      <td>DB04953</td>\n",
       "      <td>C0238097|C1095952|C0558401|C0341217|C0154446|C...</td>\n",
       "      <td>O43526|O43525|P56696|Q9NR82</td>\n",
       "      <td>P22309|P35503|P22310|O60656|P11509|P11245</td>\n",
       "      <td>hsa:3785|hsa:3786|hsa:9132|hsa:56479</td>\n",
       "      <td>9|10|11|12|14|15|18|19|23|178|182|185|189|283|...</td>\n",
       "      <td>Ezogabine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>DB08865</td>\n",
       "      <td>C0267988|C0238097|C1608967|C0158820|C0855959|C...</td>\n",
       "      <td>Q9UM73|P08581</td>\n",
       "      <td>P08684|P20815|P20813</td>\n",
       "      <td>hsa:238|hsa:4233</td>\n",
       "      <td>9|10|11|12|14|15|16|18|23|37|38|143|148|149|17...</td>\n",
       "      <td>Crizotinib</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       id                                               side   \n",
       "0        0  DB01296  C1096328|C0162830|C1611725|C0541767|C0242973|C...  \\\n",
       "1        1  DB09230  C0015371|C0949040|C0856054|C0231926|C1608969|C...   \n",
       "2        2  DB05812  C0341697|C0035232|C0855476|C0162119|C1142166|C...   \n",
       "3        3  DB01195  C1737214|C0015376|C0576091|C1536116|C0679254|C...   \n",
       "4        4  DB00201  C0423602|C0239557|C0031924|C0947912|C0600125|C...   \n",
       "..     ...      ...                                                ...   \n",
       "567    567  DB01587  C0155867|C0341697|C0231341|C0853557|C0159060|C...   \n",
       "568    568  DB00448  C0241148|C0040440|C1096403|C0011253|C0001416|C...   \n",
       "569    569  DB00559  C0030283|C0856054|C0853557|C0426597|C0026636|C...   \n",
       "570    570  DB04953  C0238097|C1095952|C0558401|C0341217|C0154446|C...   \n",
       "571    571  DB08865  C0267988|C0238097|C1608967|C0158820|C0855959|C...   \n",
       "\n",
       "                                                target   \n",
       "0                   P14780|Q00653|P01375|P01579|P33673  \\\n",
       "1                                               Q02641   \n",
       "2                                               P05093   \n",
       "3                                 Q14524|P35499|Q12809   \n",
       "4    P30542|P29274|Q07343|P21817|BE0004922|P78527|O...   \n",
       "..                                                 ...   \n",
       "567          P30536|P14867|P18505|Q8N1C3|O14764|P78334   \n",
       "568                                      P20648|P10636   \n",
       "569                                      P25101|P24530   \n",
       "570                        O43526|O43525|P56696|Q9NR82   \n",
       "571                                      Q9UM73|P08581   \n",
       "\n",
       "                                                enzyme   \n",
       "0                                        P33261|P05181  \\\n",
       "1                                               P08684   \n",
       "2     P08684|Q06520|P10635|P10632|P05177|P33261|P11712   \n",
       "3                                        P10635|P11712   \n",
       "4    P20815|P05177|P24462|P08684|P05181|P10632|P117...   \n",
       "..                                                 ...   \n",
       "567                                             P08684   \n",
       "568  P33261|P11712|P08684|P04798|P05177|Q16678|P332...   \n",
       "569                                      P08684|P11712   \n",
       "570          P22309|P35503|P22310|O60656|P11509|P11245   \n",
       "571                               P08684|P20815|P20813   \n",
       "\n",
       "                                               pathway   \n",
       "0                  hsa:4318|hsa:4791|hsa:7124|hsa:3458  \\\n",
       "1                                              hsa:782   \n",
       "2                                             hsa:1586   \n",
       "3                           hsa:6331|hsa:6329|hsa:3757   \n",
       "4    hsa:134|hsa:135|hsa:5142|hsa:6261|hsa:5591|hsa...   \n",
       "..                                                 ...   \n",
       "567  hsa:706|hsa:2554|hsa:2560|hsa:2565|hsa:2563|hs...   \n",
       "568                                   hsa:495|hsa:4137   \n",
       "569                                  hsa:1909|hsa:1910   \n",
       "570               hsa:3785|hsa:3786|hsa:9132|hsa:56479   \n",
       "571                                   hsa:238|hsa:4233   \n",
       "\n",
       "                                                 smile          name  \n",
       "0    9|10|14|18|19|20|178|181|283|284|285|286|299|3...   Glucosamine  \n",
       "1    9|10|11|12|13|14|15|16|18|19|20|129|131|132|17...  Azelnidipine  \n",
       "2    9|10|11|12|14|18|143|147|178|179|182|183|184|1...   Abiraterone  \n",
       "3    9|10|11|12|14|15|18|19|23|24|25|178|180|181|18...    Flecainide  \n",
       "4    9|10|11|14|15|16|18|19|143|148|149|178|183|184...      Caffeine  \n",
       "..                                                 ...           ...  \n",
       "567  9|10|11|12|14|15|18|19|37|178|182|183|184|185|...     Ketazolam  \n",
       "568  9|10|11|12|14|15|18|19|23|24|33|143|148|149|17...  Lansoprazole  \n",
       "569  9|10|11|12|14|15|16|18|19|20|33|178|182|183|18...      Bosentan  \n",
       "570  9|10|11|12|14|15|18|19|23|178|182|185|189|283|...     Ezogabine  \n",
       "571  9|10|11|12|14|15|16|18|23|37|38|143|148|149|17...    Crizotinib  \n",
       "\n",
       "[572 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./DS1/df.pkl','rb') as f:\n",
    "    dataset = pickle.load(file=f)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>c0000727</th>\n",
       "      <th>c0000729</th>\n",
       "      <th>c0000733</th>\n",
       "      <th>c0000734</th>\n",
       "      <th>c0000735</th>\n",
       "      <th>c0000772</th>\n",
       "      <th>c0000809</th>\n",
       "      <th>c0000810</th>\n",
       "      <th>...</th>\n",
       "      <th>840</th>\n",
       "      <th>842</th>\n",
       "      <th>845</th>\n",
       "      <th>847</th>\n",
       "      <th>860</th>\n",
       "      <th>861</th>\n",
       "      <th>863</th>\n",
       "      <th>866</th>\n",
       "      <th>93</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB01296</td>\n",
       "      <td>Glucosamine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB09230</td>\n",
       "      <td>Azelnidipine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB05812</td>\n",
       "      <td>Abiraterone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB01195</td>\n",
       "      <td>Flecainide</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB00201</td>\n",
       "      <td>Caffeine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>DB01587</td>\n",
       "      <td>Ketazolam</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>DB00448</td>\n",
       "      <td>Lansoprazole</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>DB00559</td>\n",
       "      <td>Bosentan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>DB04953</td>\n",
       "      <td>Ezogabine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>DB08865</td>\n",
       "      <td>Crizotinib</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 12899 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          name c0000727 c0000729 c0000733 c0000734 c0000735   \n",
       "0    DB01296   Glucosamine        0        0        0        1        0  \\\n",
       "1    DB09230  Azelnidipine        0        0        0        0        0   \n",
       "2    DB05812   Abiraterone        0        0        0        0        0   \n",
       "3    DB01195    Flecainide        0        0        0        0        0   \n",
       "4    DB00201      Caffeine        0        0        0        0        0   \n",
       "..       ...           ...      ...      ...      ...      ...      ...   \n",
       "567  DB01587     Ketazolam        1        0        0        1        0   \n",
       "568  DB00448  Lansoprazole        0        1        0        0        0   \n",
       "569  DB00559      Bosentan        0        0        0        1        0   \n",
       "570  DB04953     Ezogabine        0        0        0        0        0   \n",
       "571  DB08865    Crizotinib        0        0        0        0        0   \n",
       "\n",
       "    c0000772 c0000809 c0000810  ... 840 842 845 847 860 861 863 866 93 95  \n",
       "0          0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "1          0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "2          0        0        0  ...   0   0   0   0   1   0   0   0  0  0  \n",
       "3          0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "4          0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "..       ...      ...      ...  ...  ..  ..  ..  ..  ..  ..  ..  .. .. ..  \n",
       "567        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "568        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "569        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "570        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "571        0        0        0  ...   0   0   0   0   0   0   0   0  0  0  \n",
       "\n",
       "[572 rows x 12899 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = VectorizerApply(CountVectorizer)\n",
    "X = vec.fit_transform(dataset,id='id',index='index',name='name')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>action</th>\n",
       "      <th>drugA</th>\n",
       "      <th>drugB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The risk or severity of adverse effects</td>\n",
       "      <td>increase</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Amiodarone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Apalutamide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>increase</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Aprepitant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Atomoxetine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Bortezomib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37259</th>\n",
       "      <td>37259</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>increase</td>\n",
       "      <td>Nefazodone</td>\n",
       "      <td>Netupitant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37260</th>\n",
       "      <td>37260</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Nefazodone</td>\n",
       "      <td>Nicardipine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37261</th>\n",
       "      <td>37261</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>increase</td>\n",
       "      <td>Neratinib</td>\n",
       "      <td>Netupitant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37262</th>\n",
       "      <td>37262</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>increase</td>\n",
       "      <td>Netupitant</td>\n",
       "      <td>Nicardipine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37263</th>\n",
       "      <td>37263</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Nicardipine</td>\n",
       "      <td>Naproxen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37264 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                mechanism    action        drugA   \n",
       "0          0  The risk or severity of adverse effects  increase  Abemaciclib  \\\n",
       "1          1                  The serum concentration  decrease  Abemaciclib   \n",
       "2          2                  The serum concentration  increase  Abemaciclib   \n",
       "3          3                           The metabolism  decrease  Abemaciclib   \n",
       "4          4                           The metabolism  decrease  Abemaciclib   \n",
       "...      ...                                      ...       ...          ...   \n",
       "37259  37259                  The serum concentration  increase   Nefazodone   \n",
       "37260  37260                           The metabolism  decrease   Nefazodone   \n",
       "37261  37261                  The serum concentration  increase    Neratinib   \n",
       "37262  37262                  The serum concentration  increase   Netupitant   \n",
       "37263  37263                           The metabolism  decrease  Nicardipine   \n",
       "\n",
       "             drugB  \n",
       "0       Amiodarone  \n",
       "1      Apalutamide  \n",
       "2       Aprepitant  \n",
       "3      Atomoxetine  \n",
       "4       Bortezomib  \n",
       "...            ...  \n",
       "37259   Netupitant  \n",
       "37260  Nicardipine  \n",
       "37261   Netupitant  \n",
       "37262  Nicardipine  \n",
       "37263     Naproxen  \n",
       "\n",
       "[37264 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = sqlite3.connect('./DS1/event.db')\n",
    "extraction = pd.read_sql('select * from extraction;', connection)\n",
    "extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drugA</th>\n",
       "      <th>drugB</th>\n",
       "      <th>interaction</th>\n",
       "      <th>interaction_numaber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Amiodarone</td>\n",
       "      <td>The risk or severity of adverse effects increase</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Apalutamide</td>\n",
       "      <td>The serum concentration decrease</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Aprepitant</td>\n",
       "      <td>The serum concentration increase</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Atomoxetine</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>Bortezomib</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37259</th>\n",
       "      <td>Nefazodone</td>\n",
       "      <td>Netupitant</td>\n",
       "      <td>The serum concentration increase</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37260</th>\n",
       "      <td>Nefazodone</td>\n",
       "      <td>Nicardipine</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37261</th>\n",
       "      <td>Neratinib</td>\n",
       "      <td>Netupitant</td>\n",
       "      <td>The serum concentration increase</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37262</th>\n",
       "      <td>Netupitant</td>\n",
       "      <td>Nicardipine</td>\n",
       "      <td>The serum concentration increase</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37263</th>\n",
       "      <td>Nicardipine</td>\n",
       "      <td>Naproxen</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37264 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             drugA        drugB   \n",
       "0      Abemaciclib   Amiodarone  \\\n",
       "1      Abemaciclib  Apalutamide   \n",
       "2      Abemaciclib   Aprepitant   \n",
       "3      Abemaciclib  Atomoxetine   \n",
       "4      Abemaciclib   Bortezomib   \n",
       "...            ...          ...   \n",
       "37259   Nefazodone   Netupitant   \n",
       "37260   Nefazodone  Nicardipine   \n",
       "37261    Neratinib   Netupitant   \n",
       "37262   Netupitant  Nicardipine   \n",
       "37263  Nicardipine     Naproxen   \n",
       "\n",
       "                                            interaction  interaction_numaber  \n",
       "0      The risk or severity of adverse effects increase                   38  \n",
       "1                      The serum concentration decrease                   18  \n",
       "2                      The serum concentration increase                   10  \n",
       "3                               The metabolism decrease                   13  \n",
       "4                               The metabolism decrease                   13  \n",
       "...                                                 ...                  ...  \n",
       "37259                  The serum concentration increase                   10  \n",
       "37260                           The metabolism decrease                   13  \n",
       "37261                  The serum concentration increase                   10  \n",
       "37262                  The serum concentration increase                   10  \n",
       "37263                           The metabolism decrease                   13  \n",
       "\n",
       "[37264 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_creator = Label_creator()\n",
    "y = label_creator.fit_transform(extraction,index='index',mechanism='mechanism',action='action')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 0.0 %\n",
      "Process: 2.6835551738943755 %\n",
      "Process: 5.367110347788751 %\n",
      "Process: 8.050665521683126 %\n",
      "Process: 10.734220695577502 %\n",
      "Process: 13.417775869471877 %\n",
      "Process: 16.10133104336625 %\n",
      "Process: 18.784886217260627 %\n",
      "Process: 21.468441391155004 %\n",
      "Process: 24.151996565049377 %\n",
      "Process: 26.835551738943753 %\n",
      "Process: 29.51910691283813 %\n",
      "Process: 32.2026620867325 %\n",
      "Process: 34.88621726062688 %\n",
      "Process: 37.569772434521255 %\n",
      "Process: 40.25332760841563 %\n",
      "Process: 42.93688278231001 %\n",
      "Process: 45.62043795620438 %\n",
      "Process: 48.30399313009875 %\n",
      "Process: 50.98754830399314 %\n",
      "Process: 53.671103477887506 %\n",
      "Process: 56.35465865178189 %\n",
      "Process: 59.03821382567626 %\n",
      "Process: 61.721768999570635 %\n",
      "Process: 64.405324173465 %\n",
      "Process: 67.08887934735938 %\n",
      "Process: 69.77243452125376 %\n",
      "Process: 72.45598969514813 %\n",
      "Process: 75.13954486904251 %\n",
      "Process: 77.82310004293689 %\n",
      "Process: 80.50665521683126 %\n",
      "Process: 83.19021039072564 %\n",
      "Process: 85.87376556462002 %\n",
      "Process: 88.55732073851439 %\n",
      "Process: 91.24087591240875 %\n",
      "Process: 93.92443108630314 %\n",
      "Process: 96.6079862601975 %\n",
      "Process: 99.2915414340919 %\n"
     ]
    }
   ],
   "source": [
    "drug_dataset = DrugDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "if not os.path.exists('./saved_dataset/'):\n",
    "    os.makedirs('./saved_dataset/')\n",
    "\n",
    "with open('./saved_dataset/drug_dataset.pickle','wb') as f:\n",
    "    pickle.dump(drug_dataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to train and validation section\n",
    "train_size = int(0.8 * len(drug_dataset))\n",
    "val_size = len(drug_dataset) - train_size\n",
    "\n",
    "train_dataset , val_dataset = random_split(drug_dataset,lengths=[train_size,val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = augment_and_concat(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59622"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader for train loader and val loader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 1.390258842230099 Val Loss: 0.863194686692416\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 1 Train Loss: 0.8642917642900123 Val Loss: 0.7117033369615354\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 2 Train Loss: 0.7376351102902737 Val Loss: 0.6333759513247934\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 3 Train Loss: 0.6644144560956814 Val Loss: 0.584032648414885\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 4 Train Loss: 0.6105734994132717 Val Loss: 0.5484155963290914\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 5 Train Loss: 0.5664535027196237 Val Loss: 0.5037418200030859\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 6 Train Loss: 0.5235290823637767 Val Loss: 0.48228439516008154\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 7 Train Loss: 0.48050168516658603 Val Loss: 0.4453102996484916\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 8 Train Loss: 0.44092888359069377 Val Loss: 0.4255252929700163\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 9 Train Loss: 0.4065406575383179 Val Loss: 0.4004731667927534\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 10 Train Loss: 0.37255538766191654 Val Loss: 0.39821969758111647\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 11 Train Loss: 0.34471285100231663 Val Loss: 0.3607009816315233\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 12 Train Loss: 0.31630487650181066 Val Loss: 0.35306387329913774\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 13 Train Loss: 0.29301413834726714 Val Loss: 0.34564541796693987\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 14 Train Loss: 0.26767682413232485 Val Loss: 0.3263397167033072\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 15 Train Loss: 0.24345010145224266 Val Loss: 0.3221827351384249\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 16 Train Loss: 0.2257923745873317 Val Loss: 0.3087230937859211\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 17 Train Loss: 0.20849515628049647 Val Loss: 0.3054674588535541\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 18 Train Loss: 0.18950299909255894 Val Loss: 0.29895956460046763\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 19 Train Loss: 0.17392695876128766 Val Loss: 0.29151653725146254\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 20 Train Loss: 0.16067218403290703 Val Loss: 0.3019512400636649\n",
      "Epoch: 21 Train Loss: 0.14651628219655474 Val Loss: 0.28524609731386374\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 22 Train Loss: 0.1366453498468787 Val Loss: 0.2673780712191127\n",
      "saving the best model in: ./saved_dataset/model1_f3.pt ...\n",
      "Epoch: 23 Train Loss: 0.12389409466743317 Val Loss: 0.28165706307097643\n",
      "Epoch: 24 Train Loss: 0.11509209048088669 Val Loss: 0.28169785789513857\n",
      "Epoch: 25 Train Loss: 0.10815723012239596 Val Loss: 0.28532193224455427\n",
      "Epoch: 26 Train Loss: 0.1008308895620954 Val Loss: 0.2779106115187866\n",
      "Epoch: 27 Train Loss: 0.09118579143563574 Val Loss: 0.2795911577646121\n"
     ]
    }
   ],
   "source": [
    "# create model and train loop\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CPSP(12897,1,3,65).to(device=device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.0001,momentum=0.9)\n",
    "\n",
    "N_epochs = 100\n",
    "patience = 5\n",
    "save_path = './saved_dataset/model1_f3.pt'\n",
    "best_val_los = np.inf\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "    if val_loss >= best_val_los:\n",
    "        print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(epoch,\n",
    "                                                         train_loss/len(train_loader),\n",
    "                                                         val_loss/len(val_loader)))\n",
    "        patience -= 1\n",
    "        if patience <= 0:\n",
    "            break\n",
    "    else:\n",
    "        patience = 5\n",
    "        best_val_los = val_loss\n",
    "        print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(epoch,\n",
    "                                                         train_loss/len(train_loader),\n",
    "                                                         val_loss/len(val_loader)))\n",
    "        print(f'saving the best model in: {save_path} ...')\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model\n",
    "model_dict = torch.load(save_path)\n",
    "model = CPSP(12897,1,3,65).to(device=device)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.9991613833819731 \n",
      "train f_score: 0.9986538397350785 \n",
      "train precision: 0.9977454465192896 \n",
      "train recall: 0.9996218329089509\n"
     ]
    }
   ],
   "source": [
    "# calculate performance mesure for train data\n",
    "acc, f_score, precision,recall = evaluate_model(model,train_loader,device,65)\n",
    "print(\"train acc: {} \\ntrain f_score: {} \\ntrain precision: {} \\ntrain recall: {}\".format(acc, f_score, precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc: 0.92539916812022 \n",
      "val f_score: 0.8160281499407529 \n",
      "val precision: 0.8176468898019431 \n",
      "val recall: 0.8228101951409763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cerberus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# calculate performance mesure for validation data\n",
    "acc, f_score, precision,recall = evaluate_model(model,val_loader,device,65)\n",
    "print(\"val acc: {} \\nval f_score: {} \\nval precision: {} \\nval recall: {}\".format(acc, f_score, precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_loader and val_loader\n",
    "with open('./saved_dataset/train_loader1.pickle','wb') as f:\n",
    "    pickle.dump(train_loader,f)\n",
    "with open('./saved_dataset/val_loader1.pickle','wb') as f:\n",
    "    pickle.dump(val_loader,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>enzyme</th>\n",
       "      <th>smile</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DB00006</td>\n",
       "      <td>P00734</td>\n",
       "      <td>P05164</td>\n",
       "      <td>1|41|79|80|108|117|140|143|173|193|197|242|269...</td>\n",
       "      <td>Bivalirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DB00035</td>\n",
       "      <td>P30518|P37288|P47901</td>\n",
       "      <td>P23219|P35354</td>\n",
       "      <td>1|53|80|115|117|140|143|173|193|197|242|253|30...</td>\n",
       "      <td>Desmopressin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DB00091</td>\n",
       "      <td>P49069|Q96LZ3|P62937|P30405</td>\n",
       "      <td>P20815|P08684|P33261|P10635</td>\n",
       "      <td>1|5|19|38|47|80|101|115|126|132|186|208|219|22...</td>\n",
       "      <td>Cyclosporine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DB00115</td>\n",
       "      <td>Q99707|P22033|Q9UBK8|Q8IVH4|Q9Y4U1|P42898</td>\n",
       "      <td>Q96EY8|Q05599</td>\n",
       "      <td>1|35|41|45|49|75|80|84|106|140|188|192|194|197...</td>\n",
       "      <td>Cyanocobalamin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DB00118</td>\n",
       "      <td>Q14749|P17707|P31153|P35520|Q00266|P21964|Q8N1...</td>\n",
       "      <td>P05181|P19623</td>\n",
       "      <td>1|75|80|194|209|348|362|378|454|457|489|577|61...</td>\n",
       "      <td>Ademetionine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>1253</td>\n",
       "      <td>DB15444</td>\n",
       "      <td>P13569</td>\n",
       "      <td>P08684|P20815|P05177|P20813|P10632|P11712|P332...</td>\n",
       "      <td>40|45|59|67|73|80|92|114|119|130|202|295|307|3...</td>\n",
       "      <td>Elexacaftor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1254</td>\n",
       "      <td>DB15488</td>\n",
       "      <td>Q92847|P10275</td>\n",
       "      <td>P21964</td>\n",
       "      <td>13|25|31|80|104|170|176|193|222|310|315|489|55...</td>\n",
       "      <td>Echinacoside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>1255</td>\n",
       "      <td>DB15566</td>\n",
       "      <td>P04150</td>\n",
       "      <td>P08684</td>\n",
       "      <td>51|80|84|147|182|240|314|315|373|408|493|504|5...</td>\n",
       "      <td>Prednisoloneacetate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>1256</td>\n",
       "      <td>DB15598</td>\n",
       "      <td>P05106|P49281</td>\n",
       "      <td>P19224</td>\n",
       "      <td>166|253|271|314|650|656|677|715|751|787|835|84...</td>\n",
       "      <td>Ferricmaltol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>1257</td>\n",
       "      <td>DB15685</td>\n",
       "      <td>P07949|P17948|P35916|P11362|P21802|P22607</td>\n",
       "      <td>P08684|P10632|P08684</td>\n",
       "      <td>40|43|80|93|114|123|217|249|271|310|311|322|35...</td>\n",
       "      <td>Selpercatinib</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       id                                             target   \n",
       "0         0  DB00006                                             P00734  \\\n",
       "1         1  DB00035                               P30518|P37288|P47901   \n",
       "2         2  DB00091                        P49069|Q96LZ3|P62937|P30405   \n",
       "3         3  DB00115          Q99707|P22033|Q9UBK8|Q8IVH4|Q9Y4U1|P42898   \n",
       "4         4  DB00118  Q14749|P17707|P31153|P35520|Q00266|P21964|Q8N1...   \n",
       "...     ...      ...                                                ...   \n",
       "1253   1253  DB15444                                             P13569   \n",
       "1254   1254  DB15488                                      Q92847|P10275   \n",
       "1255   1255  DB15566                                             P04150   \n",
       "1256   1256  DB15598                                      P05106|P49281   \n",
       "1257   1257  DB15685          P07949|P17948|P35916|P11362|P21802|P22607   \n",
       "\n",
       "                                                 enzyme   \n",
       "0                                                P05164  \\\n",
       "1                                         P23219|P35354   \n",
       "2                           P20815|P08684|P33261|P10635   \n",
       "3                                         Q96EY8|Q05599   \n",
       "4                                         P05181|P19623   \n",
       "...                                                 ...   \n",
       "1253  P08684|P20815|P05177|P20813|P10632|P11712|P332...   \n",
       "1254                                             P21964   \n",
       "1255                                             P08684   \n",
       "1256                                             P19224   \n",
       "1257                               P08684|P10632|P08684   \n",
       "\n",
       "                                                  smile                 name  \n",
       "0     1|41|79|80|108|117|140|143|173|193|197|242|269...          Bivalirudin  \n",
       "1     1|53|80|115|117|140|143|173|193|197|242|253|30...         Desmopressin  \n",
       "2     1|5|19|38|47|80|101|115|126|132|186|208|219|22...         Cyclosporine  \n",
       "3     1|35|41|45|49|75|80|84|106|140|188|192|194|197...       Cyanocobalamin  \n",
       "4     1|75|80|194|209|348|362|378|454|457|489|577|61...         Ademetionine  \n",
       "...                                                 ...                  ...  \n",
       "1253  40|45|59|67|73|80|92|114|119|130|202|295|307|3...          Elexacaftor  \n",
       "1254  13|25|31|80|104|170|176|193|222|310|315|489|55...         Echinacoside  \n",
       "1255  51|80|84|147|182|240|314|315|373|408|493|504|5...  Prednisoloneacetate  \n",
       "1256  166|253|271|314|650|656|677|715|751|787|835|84...         Ferricmaltol  \n",
       "1257  40|43|80|93|114|123|217|249|271|310|311|322|35...        Selpercatinib  \n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./DS2/drug_information_1258.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>a0a024r8i1</th>\n",
       "      <th>a0a0e1r3h3</th>\n",
       "      <th>a0a0h2xj39</th>\n",
       "      <th>a0a0t9az62</th>\n",
       "      <th>a0a143zzk9</th>\n",
       "      <th>a0a144a2g5</th>\n",
       "      <th>a2qlk4</th>\n",
       "      <th>a5x5y0</th>\n",
       "      <th>...</th>\n",
       "      <th>99</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB00006</td>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB00035</td>\n",
       "      <td>Desmopressin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB00091</td>\n",
       "      <td>Cyclosporine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB00115</td>\n",
       "      <td>Cyanocobalamin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB00118</td>\n",
       "      <td>Ademetionine</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>DB15444</td>\n",
       "      <td>Elexacaftor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>DB15488</td>\n",
       "      <td>Echinacoside</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>DB15566</td>\n",
       "      <td>Prednisoloneacetate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>DB15598</td>\n",
       "      <td>Ferricmaltol</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>DB15685</td>\n",
       "      <td>Selpercatinib</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 3999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                 name a0a024r8i1 a0a0e1r3h3 a0a0h2xj39   \n",
       "0     DB00006          Bivalirudin          0          0          0  \\\n",
       "1     DB00035         Desmopressin          0          0          0   \n",
       "2     DB00091         Cyclosporine          0          0          0   \n",
       "3     DB00115       Cyanocobalamin          0          0          0   \n",
       "4     DB00118         Ademetionine          0          0          0   \n",
       "...       ...                  ...        ...        ...        ...   \n",
       "1253  DB15444          Elexacaftor          0          0          0   \n",
       "1254  DB15488         Echinacoside          0          0          0   \n",
       "1255  DB15566  Prednisoloneacetate          0          0          0   \n",
       "1256  DB15598         Ferricmaltol          0          0          0   \n",
       "1257  DB15685        Selpercatinib          0          0          0   \n",
       "\n",
       "     a0a0t9az62 a0a143zzk9 a0a144a2g5 a2qlk4 a5x5y0  ... 99 990 991 992 993   \n",
       "0             0          0          0      0      0  ...  0   0   0   0   0  \\\n",
       "1             0          0          0      0      0  ...  0   0   0   0   0   \n",
       "2             0          0          0      0      0  ...  0   0   0   0   0   \n",
       "3             0          0          0      0      0  ...  0   0   0   0   0   \n",
       "4             0          0          0      0      0  ...  0   0   0   0   0   \n",
       "...         ...        ...        ...    ...    ...  ... ..  ..  ..  ..  ..   \n",
       "1253          0          0          0      0      0  ...  0   0   0   0   0   \n",
       "1254          0          0          0      0      0  ...  0   0   0   0   0   \n",
       "1255          0          0          0      0      0  ...  0   0   0   0   0   \n",
       "1256          0          0          0      0      0  ...  0   0   0   0   0   \n",
       "1257          0          0          0      0      0  ...  0   0   0   0   0   \n",
       "\n",
       "     994 996 997 998 999  \n",
       "0      0   0   0   0   0  \n",
       "1      0   0   0   0   0  \n",
       "2      0   0   0   0   0  \n",
       "3      0   0   0   0   0  \n",
       "4      0   0   0   0   0  \n",
       "...   ..  ..  ..  ..  ..  \n",
       "1253   0   0   0   0   0  \n",
       "1254   0   0   0   0   0  \n",
       "1255   0   0   0   0   0  \n",
       "1256   0   0   0   0   0  \n",
       "1257   0   0   1   0   0  \n",
       "\n",
       "[1258 rows x 3999 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = VectorizerApply(CountVectorizer)\n",
    "X = vec.fit_transform(dataset,id='id',index='index',name='name')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mechanism</th>\n",
       "      <th>action</th>\n",
       "      <th>drugA</th>\n",
       "      <th>drugB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the anticoagulant activities</td>\n",
       "      <td>increase</td>\n",
       "      <td>Apixaban</td>\n",
       "      <td>Bivalirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the anticoagulant activities</td>\n",
       "      <td>increase</td>\n",
       "      <td>Dabigatranetexilate</td>\n",
       "      <td>Bivalirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The risk or severity of bleeding and hemorrhage</td>\n",
       "      <td>increase</td>\n",
       "      <td>Dasatinib</td>\n",
       "      <td>Bivalirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>the anticoagulant activities</td>\n",
       "      <td>increase</td>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>Rivaroxaban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>The risk or severity of bleeding and hemorrhage</td>\n",
       "      <td>increase</td>\n",
       "      <td>Tipranavir</td>\n",
       "      <td>Bivalirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161765</th>\n",
       "      <td>323530</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Zanubrutinib</td>\n",
       "      <td>Curcuminsulfate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161766</th>\n",
       "      <td>323531</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>increase</td>\n",
       "      <td>Elexacaftor</td>\n",
       "      <td>Betamethasonephosphate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161767</th>\n",
       "      <td>323535</td>\n",
       "      <td>The serum concentration</td>\n",
       "      <td>increase</td>\n",
       "      <td>Ubrogepant</td>\n",
       "      <td>Ripretinib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161768</th>\n",
       "      <td>323536</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Avapritinib</td>\n",
       "      <td>Voxelotor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161769</th>\n",
       "      <td>323538</td>\n",
       "      <td>The metabolism</td>\n",
       "      <td>decrease</td>\n",
       "      <td>Zanubrutinib</td>\n",
       "      <td>Elexacaftor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161770 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                        mechanism    action   \n",
       "0            0                     the anticoagulant activities  increase  \\\n",
       "1            1                     the anticoagulant activities  increase   \n",
       "2            2  The risk or severity of bleeding and hemorrhage  increase   \n",
       "3            4                     the anticoagulant activities  increase   \n",
       "4            6  The risk or severity of bleeding and hemorrhage  increase   \n",
       "...        ...                                              ...       ...   \n",
       "161765  323530                                   The metabolism  decrease   \n",
       "161766  323531                                   The metabolism  increase   \n",
       "161767  323535                          The serum concentration  increase   \n",
       "161768  323536                                   The metabolism  decrease   \n",
       "161769  323538                                   The metabolism  decrease   \n",
       "\n",
       "                      drugA                   drugB  \n",
       "0                  Apixaban             Bivalirudin  \n",
       "1       Dabigatranetexilate             Bivalirudin  \n",
       "2                 Dasatinib             Bivalirudin  \n",
       "3               Bivalirudin             Rivaroxaban  \n",
       "4                Tipranavir             Bivalirudin  \n",
       "...                     ...                     ...  \n",
       "161765         Zanubrutinib         Curcuminsulfate  \n",
       "161766          Elexacaftor  Betamethasonephosphate  \n",
       "161767           Ubrogepant              Ripretinib  \n",
       "161768          Avapritinib               Voxelotor  \n",
       "161769         Zanubrutinib             Elexacaftor  \n",
       "\n",
       "[161770 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction = pd.read_csv('./DS2/drug_interaction.csv')\n",
    "extraction = extraction.drop('Unnamed: 0',axis=1)\n",
    "extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drugA</th>\n",
       "      <th>drugB</th>\n",
       "      <th>interaction</th>\n",
       "      <th>interaction_numaber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apixaban</td>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>the anticoagulant activities increase</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dabigatranetexilate</td>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>the anticoagulant activities increase</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dasatinib</td>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>The risk or severity of bleeding and hemorrhag...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>Rivaroxaban</td>\n",
       "      <td>the anticoagulant activities increase</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tipranavir</td>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>The risk or severity of bleeding and hemorrhag...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161765</th>\n",
       "      <td>Zanubrutinib</td>\n",
       "      <td>Curcuminsulfate</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161766</th>\n",
       "      <td>Elexacaftor</td>\n",
       "      <td>Betamethasonephosphate</td>\n",
       "      <td>The metabolism increase</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161767</th>\n",
       "      <td>Ubrogepant</td>\n",
       "      <td>Ripretinib</td>\n",
       "      <td>The serum concentration increase</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161768</th>\n",
       "      <td>Avapritinib</td>\n",
       "      <td>Voxelotor</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161769</th>\n",
       "      <td>Zanubrutinib</td>\n",
       "      <td>Elexacaftor</td>\n",
       "      <td>The metabolism decrease</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161770 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      drugA                   drugB   \n",
       "0                  Apixaban             Bivalirudin  \\\n",
       "1       Dabigatranetexilate             Bivalirudin   \n",
       "2                 Dasatinib             Bivalirudin   \n",
       "3               Bivalirudin             Rivaroxaban   \n",
       "4                Tipranavir             Bivalirudin   \n",
       "...                     ...                     ...   \n",
       "161765         Zanubrutinib         Curcuminsulfate   \n",
       "161766          Elexacaftor  Betamethasonephosphate   \n",
       "161767           Ubrogepant              Ripretinib   \n",
       "161768          Avapritinib               Voxelotor   \n",
       "161769         Zanubrutinib             Elexacaftor   \n",
       "\n",
       "                                              interaction  interaction_numaber  \n",
       "0                   the anticoagulant activities increase                   92  \n",
       "1                   the anticoagulant activities increase                   92  \n",
       "2       The risk or severity of bleeding and hemorrhag...                   68  \n",
       "3                   the anticoagulant activities increase                   92  \n",
       "4       The risk or severity of bleeding and hemorrhag...                   68  \n",
       "...                                                   ...                  ...  \n",
       "161765                            The metabolism decrease                    3  \n",
       "161766                            The metabolism increase                   47  \n",
       "161767                   The serum concentration increase                    2  \n",
       "161768                            The metabolism decrease                    3  \n",
       "161769                            The metabolism decrease                    3  \n",
       "\n",
       "[161770 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_creator = Label_creator()\n",
    "y = label_creator.fit_transform(extraction,index='index',mechanism='mechanism',action='action')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 0.0 %\n",
      "Process: 0.6181615874389566 %\n",
      "Process: 1.236323174877913 %\n",
      "Process: 1.8544847623168697 %\n",
      "Process: 2.472646349755826 %\n",
      "Process: 3.090807937194783 %\n",
      "Process: 3.7089695246337393 %\n",
      "Process: 4.327131112072696 %\n",
      "Process: 4.945292699511652 %\n",
      "Process: 5.563454286950609 %\n",
      "Process: 6.181615874389566 %\n",
      "Process: 6.799777461828523 %\n",
      "Process: 7.417939049267479 %\n",
      "Process: 8.036100636706434 %\n",
      "Process: 8.654262224145391 %\n",
      "Process: 9.272423811584348 %\n",
      "Process: 9.890585399023305 %\n",
      "Process: 10.508746986462262 %\n",
      "Process: 11.126908573901218 %\n",
      "Process: 11.745070161340173 %\n",
      "Process: 12.363231748779132 %\n",
      "Process: 12.981393336218087 %\n",
      "Process: 13.599554923657045 %\n",
      "Process: 14.217716511096 %\n",
      "Process: 14.835878098534957 %\n",
      "Process: 15.454039685973914 %\n",
      "Process: 16.07220127341287 %\n",
      "Process: 16.690362860851828 %\n",
      "Process: 17.308524448290783 %\n",
      "Process: 17.926686035729738 %\n",
      "Process: 18.544847623168696 %\n",
      "Process: 19.163009210607655 %\n",
      "Process: 19.78117079804661 %\n",
      "Process: 20.399332385485565 %\n",
      "Process: 21.017493972924523 %\n",
      "Process: 21.635655560363478 %\n",
      "Process: 22.253817147802437 %\n",
      "Process: 22.87197873524139 %\n",
      "Process: 23.490140322680347 %\n",
      "Process: 24.108301910119305 %\n",
      "Process: 24.726463497558264 %\n",
      "Process: 25.34462508499722 %\n",
      "Process: 25.962786672436174 %\n",
      "Process: 26.580948259875132 %\n",
      "Process: 27.19910984731409 %\n",
      "Process: 27.817271434753042 %\n",
      "Process: 28.435433022192 %\n",
      "Process: 29.053594609630956 %\n",
      "Process: 29.671756197069914 %\n",
      "Process: 30.28991778450887 %\n",
      "Process: 30.908079371947828 %\n",
      "Process: 31.52624095938678 %\n",
      "Process: 32.14440254682574 %\n",
      "Process: 32.7625641342647 %\n",
      "Process: 33.380725721703655 %\n",
      "Process: 33.99888730914261 %\n",
      "Process: 34.617048896581565 %\n",
      "Process: 35.23521048402053 %\n",
      "Process: 35.853372071459475 %\n",
      "Process: 36.47153365889844 %\n",
      "Process: 37.08969524633739 %\n",
      "Process: 37.70785683377635 %\n",
      "Process: 38.32601842121531 %\n",
      "Process: 38.944180008654264 %\n",
      "Process: 39.56234159609322 %\n",
      "Process: 40.180503183532174 %\n",
      "Process: 40.79866477097113 %\n",
      "Process: 41.416826358410084 %\n",
      "Process: 42.034987945849046 %\n",
      "Process: 42.653149533288 %\n",
      "Process: 43.271311120726956 %\n",
      "Process: 43.88947270816592 %\n",
      "Process: 44.50763429560487 %\n",
      "Process: 45.12579588304383 %\n",
      "Process: 45.74395747048278 %\n",
      "Process: 46.36211905792174 %\n",
      "Process: 46.98028064536069 %\n",
      "Process: 47.598442232799655 %\n",
      "Process: 48.21660382023861 %\n",
      "Process: 48.834765407677565 %\n",
      "Process: 49.45292699511653 %\n",
      "Process: 50.071088582555475 %\n",
      "Process: 50.68925016999444 %\n",
      "Process: 51.3074117574334 %\n",
      "Process: 51.92557334487235 %\n",
      "Process: 52.5437349323113 %\n",
      "Process: 53.161896519750265 %\n",
      "Process: 53.78005810718922 %\n",
      "Process: 54.39821969462818 %\n",
      "Process: 55.01638128206713 %\n",
      "Process: 55.634542869506085 %\n",
      "Process: 56.25270445694505 %\n",
      "Process: 56.870866044384 %\n",
      "Process: 57.48902763182295 %\n",
      "Process: 58.10718921926191 %\n",
      "Process: 58.725350806700874 %\n",
      "Process: 59.34351239413983 %\n",
      "Process: 59.96167398157879 %\n",
      "Process: 60.57983556901774 %\n",
      "Process: 61.197997156456694 %\n",
      "Process: 61.816158743895656 %\n",
      "Process: 62.43432033133461 %\n",
      "Process: 63.05248191877356 %\n",
      "Process: 63.67064350621252 %\n",
      "Process: 64.28880509365148 %\n",
      "Process: 64.90696668109044 %\n",
      "Process: 65.5251282685294 %\n",
      "Process: 66.14328985596835 %\n",
      "Process: 66.76145144340731 %\n",
      "Process: 67.37961303084626 %\n",
      "Process: 67.99777461828522 %\n",
      "Process: 68.61593620572418 %\n",
      "Process: 69.23409779316313 %\n",
      "Process: 69.85225938060209 %\n",
      "Process: 70.47042096804105 %\n",
      "Process: 71.08858255548 %\n",
      "Process: 71.70674414291895 %\n",
      "Process: 72.32490573035791 %\n",
      "Process: 72.94306731779687 %\n",
      "Process: 73.56122890523584 %\n",
      "Process: 74.17939049267478 %\n",
      "Process: 74.79755208011373 %\n",
      "Process: 75.4157136675527 %\n",
      "Process: 76.03387525499166 %\n",
      "Process: 76.65203684243062 %\n",
      "Process: 77.27019842986957 %\n",
      "Process: 77.88836001730853 %\n",
      "Process: 78.50652160474748 %\n",
      "Process: 79.12468319218644 %\n",
      "Process: 79.7428447796254 %\n",
      "Process: 80.36100636706435 %\n",
      "Process: 80.97916795450331 %\n",
      "Process: 81.59732954194226 %\n",
      "Process: 82.21549112938122 %\n",
      "Process: 82.83365271682017 %\n",
      "Process: 83.45181430425913 %\n",
      "Process: 84.06997589169809 %\n",
      "Process: 84.68813747913705 %\n",
      "Process: 85.306299066576 %\n",
      "Process: 85.92446065401495 %\n",
      "Process: 86.54262224145391 %\n",
      "Process: 87.16078382889287 %\n",
      "Process: 87.77894541633184 %\n",
      "Process: 88.39710700377078 %\n",
      "Process: 89.01526859120975 %\n",
      "Process: 89.6334301786487 %\n",
      "Process: 90.25159176608766 %\n",
      "Process: 90.86975335352662 %\n",
      "Process: 91.48791494096557 %\n",
      "Process: 92.10607652840453 %\n",
      "Process: 92.72423811584348 %\n",
      "Process: 93.34239970328244 %\n",
      "Process: 93.96056129072139 %\n",
      "Process: 94.57872287816035 %\n",
      "Process: 95.19688446559931 %\n",
      "Process: 95.81504605303827 %\n",
      "Process: 96.43320764047722 %\n",
      "Process: 97.05136922791617 %\n",
      "Process: 97.66953081535513 %\n",
      "Process: 98.2876924027941 %\n",
      "Process: 98.90585399023306 %\n",
      "Process: 99.524015577672 %\n"
     ]
    }
   ],
   "source": [
    "drug_dataset = DrugDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "if not os.path.exists('./saved_dataset/'):\n",
    "    os.makedirs('./saved_dataset/')\n",
    "\n",
    "with open('./saved_dataset/drug_dataset2.pickle','wb') as f:\n",
    "    pickle.dump(drug_dataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to train and validation section\n",
    "train_size = int(0.8 * len(drug_dataset))\n",
    "val_size = len(drug_dataset) - train_size\n",
    "\n",
    "train_dataset , val_dataset = random_split(drug_dataset,lengths=[train_size,val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = augment_and_concat(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258832"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader for train loader and val loader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 0.23859053163446609 Val Loss: 0.444650853078631\n",
      "Epoch: 1 Train Loss: 0.23144505278178518 Val Loss: 0.47736695995553174\n",
      "Epoch: 2 Train Loss: 0.22572299693871437 Val Loss: 0.4603695822769184\n",
      "Epoch: 3 Train Loss: 0.2193316174973876 Val Loss: 0.45163489135766693\n",
      "Epoch: 4 Train Loss: 0.2151270854184582 Val Loss: 0.46552097648326946\n",
      "Epoch: 5 Train Loss: 0.20661479761026252 Val Loss: 0.4534956604590823\n",
      "Epoch: 6 Train Loss: 0.20350696123962542 Val Loss: 0.45233616900030205\n"
     ]
    }
   ],
   "source": [
    "# create model and train loop\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CPSP(3997,1,3,100).to(device=device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.0001,momentum=0.9)\n",
    "\n",
    "N_epochs = 100\n",
    "patience = 7\n",
    "save_path = './saved_dataset/model2_f.pt'\n",
    "best_val_los = np.inf\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "    if val_loss >= best_val_los:\n",
    "        print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(epoch,\n",
    "                                                         train_loss/len(train_loader),\n",
    "                                                         val_loss/len(val_loader)))\n",
    "        patience -= 1\n",
    "        if patience <= 0:\n",
    "            break\n",
    "    else:\n",
    "        patience = 7\n",
    "        best_val_los = val_loss\n",
    "        print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(epoch,\n",
    "                                                         train_loss/len(train_loader),\n",
    "                                                         val_loss/len(val_loader)))\n",
    "        print(f'saving the best model in: {save_path} ...')\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model\n",
    "model_dict = torch.load(save_path)\n",
    "model = CPSP(3997,1,3,100).to(device=device)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.9796161216542004 \n",
      "train f_score: 0.9843218446108337 \n",
      "train precision: 0.9739868137305093 \n",
      "train recall: 0.995499106184536\n"
     ]
    }
   ],
   "source": [
    "# calculate performance mesure for train data\n",
    "acc, f_score, precision,recall = evaluate_model(model,train_loader,device,100)\n",
    "print(\"train acc: {} \\ntrain f_score: {} \\ntrain precision: {} \\ntrain recall: {}\".format(acc, f_score, precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc: 0.8687024788279656 \n",
      "val f_score: 0.828722719277672 \n",
      "val precision: 0.828177835600361 \n",
      "val recall: 0.8506997108877142\n"
     ]
    }
   ],
   "source": [
    "# calculate performance mesure for validation data\n",
    "acc, f_score, precision,recall = evaluate_model(model,val_loader,device,100)\n",
    "print(\"val acc: {} \\nval f_score: {} \\nval precision: {} \\nval recall: {}\".format(acc, f_score, precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_loader and val_loader\n",
    "with open('./saved_dataset/train_loader2.pickle','wb') as f:\n",
    "    pickle.dump(train_loader,f)\n",
    "with open('./saved_dataset/val_loader2.pickle','wb') as f:\n",
    "    pickle.dump(val_loader,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with adam and max pooling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning module\n",
    "\n",
    "class CPSP1(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,feature_size,in_channels,conv_mid_channel,out_dim,*args, **kwargs) -> None:\n",
    "        super(CPSP,self).__init__(*args, **kwargs)\n",
    "        self.conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=conv_mid_channel,kernel_size=(2,3),stride=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(conv_mid_channel)\n",
    "        self.conv1_1 = torch.nn.Conv2d(in_channels=conv_mid_channel,out_channels=1, kernel_size=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(1)\n",
    "        self.fc1 = torch.nn.Linear((feature_size-3)//1 + 1, 2048)\n",
    "        self.fc2 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc3 = torch.nn.Linear(1024, out_dim)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.5)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1_1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = torch.nn.functional.\n",
    "        x = self.bn2(x)\n",
    "        x = x.view(-1,int(x.nelement() / x.shape[0]))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
